{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries have been loaded\n"
     ]
    }
   ],
   "source": [
    "__imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Additional Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import lightgbm as lgb\n",
    "from features import woe\n",
    "\n",
    "basepath   = os.path.expanduser('../')\n",
    "\n",
    "# train and validation fold\n",
    "# TRAIN_PATH = os.path.join(basepath, 'data/processed/application_train_fold.feather')\n",
    "# TEST_PATH  = os.path.join(basepath, 'data/processed/application_val_fold.feather')\n",
    "\n",
    "# full training\n",
    "TRAIN_PATH = os.path.join(basepath, 'data/processed/application_train.feather')\n",
    "TEST_PATH  = os.path.join(basepath, 'data/processed/application_test.feather')\n",
    "\n",
    "# MODEL PRESET\n",
    "MODEL_PRESET   = 'M25'\n",
    "\n",
    "# DATASET PREFIX\n",
    "# DATASET_PREFIX = 'tr'\n",
    "DATASET_PREFIX  = 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 599 ms, sys: 1.35 s, total: 1.95 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tr = pd.read_feather(f'{TRAIN_PATH}')\n",
    "te = pd.read_feather(f'{TEST_PATH}')\n",
    "\n",
    "# Application data from previous loans\n",
    "bureau       = pd.read_feather(os.path.join(basepath, 'data/processed/bureau.feather'))\n",
    "bureau_bal   = pd.read_feather(os.path.join(basepath, 'data/processed/bureau_balance.feather'))\n",
    "prev_app     = pd.read_pickle(os.path.join(basepath, 'data/processed/prev_app.pkl'))\n",
    "pos_cash     = pd.read_pickle(os.path.join(basepath, 'data/processed/pos_cash.pkl'))\n",
    "credit_bal   = pd.read_pickle(os.path.join(basepath, 'data/processed/credit_card_balance.pkl'))\n",
    "installments = pd.read_pickle(os.path.join(basepath, 'data/processed/installments_payments.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat training and test set\n",
    "data   = pd.concat((tr, te))\n",
    "ntrain = len(tr) \n",
    "\n",
    "del tr, te\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AGG_FEATURES = ['mean', 'median', 'max', 'min', 'var', 'sum']\n",
    "\n",
    "def get_agg_features(data, gp, f, on):\n",
    "    agg         = gp.groupby(on)[f]\\\n",
    "                        .agg({np.mean, np.median, np.max, np.min, np.var, np.sum}).fillna(-1)\n",
    "    \n",
    "    cols        = [f'{AGG_FEATURES[i]}_{f}_{c}' for i, c in enumerate(agg.columns)]\n",
    "    agg.columns = cols\n",
    "    agg         = agg.reset_index()\n",
    "    data        = data.merge(agg, on=on, how='left')\n",
    "    \n",
    "    del agg\n",
    "    gc.collect();\n",
    "    \n",
    "    return data, cols    \n",
    "\n",
    "def log_features(data, features):\n",
    "    for f in features:\n",
    "        data.loc[:, f] = data[f].map(lambda x: np.log(x + 1))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# deviation in three external scores\n",
    "data.loc[:, 'EXT_SOURCE_DEV']  = data.loc[:, ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].apply(np.std, axis=1)\n",
    "\n",
    "# sum of external scores\n",
    "data.loc[:, 'EXT_SOURCE_SUM'] = data['EXT_SOURCE_1'].fillna(0) + data['EXT_SOURCE_2'].fillna(0) + data['EXT_SOURCE_3'].fillna(0)\n",
    "\n",
    "# mean of external scores\n",
    "data.loc[:, 'MEAN_EXTERNAL_SCORE'] = (data['EXT_SOURCE_1'].fillna(0) + data['EXT_SOURCE_2'].fillna(0) + data['EXT_SOURCE_3'].fillna(0)) / 3\n",
    "\n",
    "# number of null values in an application\n",
    "data.loc[:, 'num_nulls'] = data.isnull().sum(axis=1)\n",
    "\n",
    "# feature interactions\n",
    "data.loc[:, 'EXT_3_1'] = data.loc[:, 'EXT_SOURCE_3'] / data.loc[:, 'EXT_SOURCE_1']\n",
    "data.loc[:, 'EXT_3_2'] = data.loc[:, 'EXT_SOURCE_3'] / data.loc[:, 'EXT_SOURCE_2']\n",
    "data.loc[:, 'EXT_2_1'] = data.loc[:, 'EXT_SOURCE_2'] / data.loc[:, 'EXT_SOURCE_1']\n",
    "\n",
    "# relationship between amount credit and total income\n",
    "data.loc[:, 'ratio_credit_income'] = data.loc[:, 'AMT_CREDIT'] / data.loc[:, 'AMT_INCOME_TOTAL']\n",
    "\n",
    "# relationship between annual amount to be paid and income\n",
    "data.loc[:, 'ratio_annuity_income'] = data.loc[:, 'AMT_ANNUITY'] / data.loc[:, 'AMT_INCOME_TOTAL']\n",
    "\n",
    "# relationship between amount annuity and age\n",
    "data.loc[:, 'ratio_annuity_age'] = data.loc[:, 'AMT_ANNUITY'] / (-data.loc[:, 'DAYS_BIRTH'] / 365)\n",
    "\n",
    "# number of missing values in an application\n",
    "data.loc[:, 'num_missing_values'] = data.loc[:, data.columns.drop('TARGET')].isnull().sum(axis=1).values\n",
    "\n",
    "# feature interaction between age and days employed\n",
    "data.loc[:, 'age_plus_employed']  = data.loc[:, 'DAYS_BIRTH'] + data.loc[:, 'DAYS_EMPLOYED']\n",
    "data.loc[:, 'ratio_age_employed'] = (data.DAYS_EMPLOYED) / (data.DAYS_BIRTH)\n",
    "\n",
    "# ratio of value of goods against which loan is given to total income\n",
    "data.loc[:, 'ratio_goods_income'] = data.loc[:, 'AMT_GOODS_PRICE'] / data.loc[:, 'AMT_INCOME_TOTAL']\n",
    "\n",
    "# feature interaction between value of goods against which loan is given to annual loan amount to be paid\n",
    "data.loc[:, 'ratio_goods_annuity'] = data.loc[:, 'AMT_GOODS_PRICE'] / data.loc[:, 'AMT_ANNUITY']\n",
    "data.loc[:, 'mult_goods_annuity']  = data.loc[:, 'AMT_GOODS_PRICE'] * data.loc[:, 'AMT_ANNUITY']\n",
    "\n",
    "# feature interaction value of goods and amount credit\n",
    "data.loc[:, 'ratio_goods_credit'] = (data.loc[:, 'AMT_GOODS_PRICE'] / data.loc[:, 'AMT_CREDIT']).replace([np.inf, -np.inf], np.nan)\n",
    "data.loc[:, 'mult_goods_credit']  = (data.loc[:, 'AMT_GOODS_PRICE'] * data.loc[:, 'AMT_CREDIT']).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# feature interaction between annuity and amount credit\n",
    "data.loc[:, 'ratio_annuity_credit'] = data.loc[:, 'AMT_ANNUITY'] / data.loc[:, 'AMT_CREDIT'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# feature interaction between amount credit and age\n",
    "data.loc[:, 'ratio_credit_age'] = data.AMT_CREDIT / (-data.DAYS_BIRTH / 365)\n",
    "\n",
    "# feature interaction between amount credit and days before application id was changed\n",
    "data.loc[:, 'ratio_credit_id_change'] = (data.AMT_CREDIT / -data.DAYS_ID_PUBLISH).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# feature interaction between days id publish and age\n",
    "data.loc[:, 'ratio_id_change_age'] = (data.DAYS_ID_PUBLISH / (-data.DAYS_BIRTH / 365))\n",
    "\n",
    "# ratio of annuity and external score\n",
    "data.loc[:, 'ratio_annuity_score_1'] = (data.loc[:, 'AMT_ANNUITY'] / data.loc[:, 'EXT_SOURCE_1']).replace([np.inf, -np.inf], np.nan)\n",
    "data.loc[:, 'ratio_annuity_score_2'] = (data.loc[:, 'AMT_ANNUITY'] / data.loc[:, 'EXT_SOURCE_2']).replace([np.inf, -np.inf], np.nan)\n",
    "data.loc[:, 'ratio_annuity_score_3'] = (data.loc[:, 'AMT_ANNUITY'] / data.loc[:, 'EXT_SOURCE_3']).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# ratio of annuity, credit multiplied by external scores\n",
    "data.loc[:, 'ratio_credit_annuity_score_1'] = ((data.loc[:, 'AMT_ANNUITY'] / data.loc[:, 'AMT_CREDIT']) * data.loc[:, 'EXT_SOURCE_1']).replace([np.inf, -np.inf], np.nan)\n",
    "data.loc[:, 'ratio_credit_annuity_score_2'] = ((data.loc[:, 'AMT_ANNUITY'] / data.loc[:, 'AMT_CREDIT']) * data.loc[:, 'EXT_SOURCE_2']).replace([np.inf, -np.inf], np.nan)\n",
    "data.loc[:, 'ratio_credit_annuity_score_3'] = ((data.loc[:, 'AMT_ANNUITY'] / data.loc[:, 'AMT_CREDIT']) * data.loc[:, 'EXT_SOURCE_3']).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "\n",
    "# ratio of owner's car age with his age\n",
    "data.loc[:, 'ratio_car_person_age'] = (data.OWN_CAR_AGE / -data.DAYS_BIRTH)\n",
    "\n",
    "# difference credit and income\n",
    "data.loc[:, 'diff_credit_income'] = data.AMT_CREDIT - data.AMT_INCOME_TOTAL\n",
    "\n",
    "# difference income total and annuity\n",
    "data.loc[:, 'diff_income_annuity']  = data.AMT_ANNUITY - data.AMT_INCOME_TOTAL\n",
    "\n",
    "# difference credit and goods price\n",
    "data.loc[:, 'diff_credit_goods'] = data.AMT_CREDIT - data.AMT_GOODS_PRICE\n",
    "\n",
    "# max, mean, std of featur groups related to days before any document was modified or changed\n",
    "if os.path.exists(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_max_doc_modified.pkl')):\n",
    "    data.loc[:, 'max_document_modified'] = pd.read_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_max_doc_modified.pkl'))\n",
    "else:\n",
    "    max_document_modified = data.loc[:, ['DAYS_REGISTRATION',\n",
    "                                         'DAYS_ID_PUBLISH',\n",
    "                                         'DAYS_LAST_PHONE_CHANGE'\n",
    "                                        ]].apply(np.max, axis=1)\n",
    "    \n",
    "    max_document_modified.to_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_max_doc_modified.pkl'))\n",
    "    data.loc[:, 'max_document_modified'] = max_document_modified\n",
    "    \n",
    "    del max_document_modified\n",
    "    gc.collect();\n",
    "    \n",
    "if os.path.exists(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_mean_doc_modified.pkl')):\n",
    "    data.loc[:, 'mean_document_modified'] = pd.read_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_mean_doc_modified.pkl'))\n",
    "else:\n",
    "    mean_document_modified = data.loc[:, ['DAYS_REGISTRATION',\n",
    "                                         'DAYS_ID_PUBLISH',\n",
    "                                         'DAYS_LAST_PHONE_CHANGE'\n",
    "                                        ]].apply(np.mean, axis=1)\n",
    "    \n",
    "    mean_document_modified.to_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_mean_doc_modified.pkl'))\n",
    "    data.loc[:, 'mean_document_modified'] = mean_document_modified\n",
    "    \n",
    "    del mean_document_modified\n",
    "    gc.collect();\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_std_doc_modified.pkl')):\n",
    "    data.loc[:, 'std_document_modified'] = pd.read_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_std_doc_modified.pkl'))\n",
    "else:\n",
    "    std_document_modified = data.loc[:, ['DAYS_REGISTRATION',\n",
    "                                         'DAYS_ID_PUBLISH',\n",
    "                                         'DAYS_LAST_PHONE_CHANGE'\n",
    "                                        ]].apply(np.std, axis=1)\n",
    "    \n",
    "    std_document_modified.to_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_std_doc_modified.pkl'))\n",
    "    data.loc[:, 'std_document_modified'] = std_document_modified\n",
    "    \n",
    "    del std_document_modified\n",
    "    gc.collect();\n",
    "    \n",
    "\n",
    "# combine feature groups\n",
    "if os.path.exists(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_flag_document.pkl')):\n",
    "    data.loc[:, 'flag_document_summary'] = pd.read_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_flag_document.pkl'))\n",
    "else:\n",
    "    flag_document_summary = data.loc[:, [f for f in data.columns if 'FLAG' in f]].apply(np.sum, axis=1)\n",
    "    data.loc[:, 'flag_document_summary'] = flag_document_summary\n",
    "    \n",
    "    del flag_document_summary\n",
    "    gc.collect();\n",
    "    \n",
    "\n",
    "if os.path.exists(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_amt_reqd_credit.pkl')):\n",
    "    data.loc[:, 'amt_reqd_summary_summary'] = pd.read_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_amt_reqd_credit.pkl'))\n",
    "else:\n",
    "    amt_reqd_credit_summary = data.loc[:, [f for f in data.columns if 'AMT_REQD_CREDIT' in f]].apply(np.sum, axis=1)\n",
    "    data.loc[:, 'amt_reqd_summary_summary'] = amt_reqd_credit_summary\n",
    "    \n",
    "    del amt_reqd_credit_summary\n",
    "    gc.collect();\n",
    "\n",
    "    \n",
    "##########################################################################################################\n",
    "#                            BUREAU                                                                      #\n",
    "##########################################################################################################\n",
    "\n",
    "# number of previous loans for a particular user\n",
    "prev_num_loans = bureau.groupby('SK_ID_CURR').size()\n",
    "\n",
    "# number of previous active credits\n",
    "num_active_credits = bureau.groupby('SK_ID_CURR')['CREDIT_ACTIVE'].sum()\n",
    "\n",
    "# aggregation features\n",
    "data, dc_cols  = get_agg_features(data, bureau, 'DAYS_CREDIT', 'SK_ID_CURR')\n",
    "data, acm_cols = get_agg_features(data, bureau, 'AMT_CREDIT_SUM', 'SK_ID_CURR')\n",
    "\n",
    "# logarithm of features\n",
    "data  = log_features(data, acm_cols)\n",
    "\n",
    "# mean number of days overdue on any previous credit\n",
    "mean_days_overdue = bureau.groupby('SK_ID_CURR')['CREDIT_DAY_OVERDUE'].mean()\n",
    "\n",
    "# mean number of days of CB credit at the time of application\n",
    "mean_days_credit_end = bureau.groupby('SK_ID_CURR')['DAYS_CREDIT_ENDDATE'].mean()\n",
    "\n",
    "# mean of maximum amount overdue on any credit line\n",
    "mean_max_amt_overdue = bureau.groupby('SK_ID_CURR')['AMT_CREDIT_MAX_OVERDUE'].mean().map(lambda x: np.log(x + 1))\n",
    "\n",
    "# mean of total amount overdue on any credit line\n",
    "mean_total_amt_overdue = bureau.groupby('SK_ID_CURR')['AMT_CREDIT_SUM_OVERDUE'].mean().map(lambda x: np.log(x + 1))\n",
    "\n",
    "# sum of num times credit was prolonged\n",
    "sum_num_times_prolonged = bureau.groupby('SK_ID_CURR')['CNT_CREDIT_PROLONG'].sum()\n",
    "\n",
    "# number of different types of credit taken from CREDIT BUREAU\n",
    "num_diff_credits = bureau.groupby('SK_ID_CURR')['CREDIT_TYPE'].nunique()\n",
    "\n",
    "# mean number of days of last credit update\n",
    "mean_days_credit_update = bureau.groupby('SK_ID_CURR')['DAYS_CREDIT_UPDATE'].mean()    \n",
    "    \n",
    "# summary of amount of annuity of credit bureau loans\n",
    "mean_cb_credit_annuity = bureau.groupby('SK_ID_CURR')['AMT_ANNUITY'].mean().map(lambda x: np.log(x + 1))\n",
    "std_cb_credit_annuity  = bureau.groupby('SK_ID_CURR')['AMT_ANNUITY'].std().map(lambda x: np.log(x + 1))\n",
    "\n",
    "# latest application reported to Home Credit\n",
    "latest_credit = bureau.groupby('SK_ID_CURR')['DAYS_CREDIT'].max()\n",
    "data.loc[:, 'latest_credit'] = data.SK_ID_CURR.map(latest_credit)\n",
    "\n",
    "# day before current application date\n",
    "credit_duration = (bureau.DAYS_CREDIT_ENDDATE - bureau.DAYS_CREDIT).map(np.abs).groupby(bureau.SK_ID_CURR).mean()\n",
    "data.loc[:, 'credit_duration'] = data.SK_ID_CURR.map(credit_duration).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# deviation in difference between remaining duration of credit and how long before we applied for this credit\n",
    "diff_prev_curr_credit = bureau.DAYS_CREDIT_ENDDATE.fillna(0) - bureau.DAYS_CREDIT.fillna(0)\n",
    "diff_prev_curr_credit = diff_prev_curr_credit.groupby(bureau.SK_ID_CURR).std()\n",
    "data.loc[:, 'std_diff_prev_curr_credit'] = data.SK_ID_CURR.map(diff_prev_curr_credit)\n",
    "\n",
    "\n",
    "# mean of difference between remaining duration of credit and how long before we applied for this credit\n",
    "diff_prev_curr_credit = bureau.DAYS_CREDIT_ENDDATE - bureau.DAYS_CREDIT\n",
    "diff_prev_curr_credit = diff_prev_curr_credit.groupby(bureau.SK_ID_CURR).mean()\n",
    "data.loc[:, 'mean_diff_prev_curr_credit'] = data.SK_ID_CURR.map(diff_prev_curr_credit)\n",
    "\n",
    "# mean of difference between days since cb credit ended and how long before we applied for current credit\n",
    "diff_prev_curr_credit = bureau.DAYS_ENDDATE_FACT - bureau.DAYS_CREDIT\n",
    "diff_prev_curr_credit = diff_prev_curr_credit.groupby(bureau.SK_ID_CURR).mean()\n",
    "data.loc[:, 'mean_diff_ended_curr_credit'] = data.SK_ID_CURR.map(diff_prev_curr_credit)\n",
    "\n",
    "# mean of difference between days last credit ended and remaining duration of credit\n",
    "diff_prev_curr_credit = bureau.DAYS_ENDDATE_FACT - bureau.DAYS_CREDIT_ENDDATE\n",
    "diff_prev_curr_credit = diff_prev_curr_credit.groupby(bureau.SK_ID_CURR).mean()\n",
    "data.loc[:, 'mean_diff_prev_remaining_credit'] = data.SK_ID_CURR.map(diff_prev_curr_credit)\n",
    "\n",
    "# mean of ratio of two differences\n",
    "diff1 = bureau.DAYS_ENDDATE_FACT - bureau.DAYS_CREDIT\n",
    "diff2 = bureau.DAYS_CREDIT_ENDDATE - bureau.DAYS_CREDIT\n",
    "diff  = (diff1 / diff2).replace([np.inf, -np.inf], np.nan)\n",
    "diff  = diff.groupby(bureau.SK_ID_CURR).mean()\n",
    "data.loc[:, 'ratio_two_diff'] = data.SK_ID_CURR.map(diff)\n",
    "\n",
    "# number of null values in days credit end date\n",
    "if os.path.exists(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_num_nulls_enddate.pkl')):\n",
    "    num_nulls_enddate = pd.read_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_num_nulls_enddate.pkl'))\n",
    "else:    \n",
    "    num_nulls_enddate = bureau.groupby('SK_ID_CURR')['DAYS_CREDIT_ENDDATE'].apply(lambda x: x.isnull().sum())\n",
    "    num_nulls_enddate.to_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_num_nulls_enddate.pkl'))\n",
    "\n",
    "data.loc[:, 'num_nulls_enddate'] = data.SK_ID_CURR.map(num_nulls_enddate).fillna(-99).astype(np.int8)\n",
    "\n",
    "# ratio of debt to total credit sum\n",
    "ratio_debt_total                = (bureau.AMT_CREDIT_SUM_DEBT / (bureau.AMT_CREDIT_SUM + 1))\n",
    "ratio_debt_total                = ratio_debt_total.groupby(bureau.SK_ID_CURR).mean()\n",
    "data.loc[:, 'ratio_debt_total'] = data.SK_ID_CURR.map(ratio_debt_total)\n",
    "\n",
    "\n",
    "# merge back with original dataframe\n",
    "data.loc[:, 'num_prev_loans']           = data.SK_ID_CURR.map(prev_num_loans).fillna(0).values\n",
    "data.loc[:, 'num_prev_active_credits']  = data.SK_ID_CURR.map(num_active_credits).fillna(0).values\n",
    "data.loc[:, 'mean_credit_days_overdue'] = data.SK_ID_CURR.map(mean_days_overdue).fillna(0).values\n",
    "data.loc[:, 'mean_days_credit_end']     = data.SK_ID_CURR.map(mean_days_credit_end).fillna(0).values\n",
    "data.loc[:, 'mean_max_amt_overdue']     = data.SK_ID_CURR.map(mean_max_amt_overdue).fillna(0).values\n",
    "data.loc[:, 'mean_total_amt_overdue']   = data.SK_ID_CURR.map(mean_total_amt_overdue).values\n",
    "data.loc[:, 'sum_num_times_prolonged']  = data.SK_ID_CURR.map(sum_num_times_prolonged).fillna(0).astype(np.int8).values\n",
    "data.loc[:, 'mean_cb_credit_annuity']   = data.SK_ID_CURR.map(mean_cb_credit_annuity).fillna(0).values\n",
    "data.loc[:, 'std_cb_credit_annuity']    = data.SK_ID_CURR.map(std_cb_credit_annuity).fillna(0).values\n",
    "data.loc[:, 'num_diff_credits']         = data.SK_ID_CURR.map(num_diff_credits).fillna(0).values\n",
    "data.loc[:, 'mean_days_credit_update']  = data.SK_ID_CURR.map(mean_days_credit_update).fillna(0).values\n",
    "\n",
    "# load ratio credit overdue to credit sum\n",
    "# ratio_credit_overdue_sum = pd.read_pickle(os.path.join(basepath, 'data/processed/bureau_ratio_overdue_sum_credit.pkl'))\n",
    "# data.loc[:, 'ratio_cedit_overdue_sum'] = data.SK_ID_CURR.map(ratio_credit_overdue_sum).fillna(-1)\n",
    "\n",
    "# interaction between credit amount and duration of credit\n",
    "credit_times_duration = (bureau.AMT_CREDIT_SUM.fillna(0) *\\\n",
    "                         (bureau.DAYS_CREDIT_ENDDATE - bureau.DAYS_CREDIT).map(np.abs))\\\n",
    "                        .replace([np.inf, -np.inf], np.nan)\n",
    "credit_times_duration = credit_times_duration.groupby(bureau.SK_ID_CURR).mean()\n",
    "data.loc[:, 'credit_times_duration'] = data.SK_ID_CURR.map(credit_times_duration)\n",
    "\n",
    "\n",
    "#############################################################################################################\n",
    "#                      FEATURE INTERACTIONS                                                                 #\n",
    "#############################################################################################################\n",
    "\n",
    "# feature interaction between credit bureau annuity, current annuity and total income\n",
    "data.loc[:, 'ratio_cb_goods_annuity'] = (data.AMT_GOODS_PRICE / (data.mean_cb_credit_annuity + data.AMT_ANNUITY)).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# feature interaction between mean days credit update and last time id was changed by user\n",
    "data.loc[:, 'ratio_update_id']        = (data.mean_days_credit_update / data.DAYS_ID_PUBLISH).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# feature interaction between mean credit amount of previous credits with current credit\n",
    "data.loc[:, 'ratio_curr_prev_credit'] = data.AMT_CREDIT / data.mean_AMT_CREDIT_SUM_mean\n",
    "\n",
    "#############################################################################################################\n",
    "#                           BUREAU and BUREAU BALANCE                                                       #\n",
    "#############################################################################################################\n",
    "\n",
    "prev_bal = bureau.loc[:, ['SK_ID_CURR', 'SK_ID_BUREAU']].merge(bureau_bal,\n",
    "                                                   on='SK_ID_BUREAU',\n",
    "                                                   how='left'\n",
    "                                                  )\n",
    "\n",
    "mean_status                      = prev_bal.groupby('SK_ID_BUREAU')['STATUS'].mean().fillna(-1)\n",
    "bureau.loc[:, 'mean_status'] = bureau.SK_ID_BUREAU.map(mean_status).values\n",
    "\n",
    "mean_status                = bureau.groupby('SK_ID_CURR')['mean_status'].mean()\n",
    "data.loc[:, 'mean_status'] = data.SK_ID_CURR.map(mean_status).values\n",
    "\n",
    "# previous loans history\n",
    "credit_history                = prev_bal.groupby('SK_ID_CURR').size().fillna(0)\n",
    "data.loc[:, 'credit_history'] = data.SK_ID_CURR.map(credit_history).values \n",
    "\n",
    "#############################################################################################################\n",
    "#                          PREVIOUS APPLICATION                                                             #\n",
    "#############################################################################################################\n",
    "\n",
    "# number of previous applications\n",
    "num_prev_apps                = prev_app.groupby('SK_ID_CURR').size()\n",
    "data.loc[:, 'num_prev_apps'] = data.SK_ID_CURR.map(num_prev_apps).fillna(0).astype(np.int8) \n",
    "\n",
    "# mean amount to be paid annually for previous applications\n",
    "prev_app_mean_annuity        = prev_app.groupby('SK_ID_CURR')['AMT_ANNUITY'].mean().map(lambda x: np.log(x + 1))\n",
    "prev_app_mean_annuity        = data.SK_ID_CURR.map(prev_app_mean_annuity)\n",
    "\n",
    "# ratio of previous annuity to current annuity\n",
    "data.loc[:, 'ratio_prev_curr_annuity'] = (prev_app_mean_annuity / data.AMT_ANNUITY).replace([np.inf, -np.inf], np.nan)\n",
    "data.loc[:, 'diff_prev_curr_annuity']  = (prev_app_mean_annuity - data.AMT_ANNUITY).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "\n",
    "# ratio of down payment amount to application amount sum\n",
    "if os.path.exists(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_down_payment_to_application.pkl')):\n",
    "    down_payment_to_application = pd.read_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_down_payment_to_application.pkl'))\n",
    "else:    \n",
    "    down_payment_to_application = prev_app.groupby('SK_ID_CURR').apply(lambda x: (x['AMT_DOWN_PAYMENT'].fillna(0) / x['AMT_APPLICATION']).sum())\n",
    "    down_payment_to_application.to_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_down_payment_to_application.pkl'))\n",
    "\n",
    "data.loc[:, 'down_payment_to_application'] = data.SK_ID_CURR.map(down_payment_to_application)\n",
    "\n",
    "# mean interest rate on down payments of previous applications\n",
    "mean_down_payment_rate                = prev_app.groupby('SK_ID_CURR')['RATE_DOWN_PAYMENT'].mean()\n",
    "data.loc[:, 'mean_down_payment_rate'] = data.SK_ID_CURR.map(mean_down_payment_rate)\n",
    "\n",
    "# most frequent rejection reason\n",
    "if os.path.exists(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_most_freq_reject_reason.pkl')):\n",
    "    most_freq_rejection_reason = pd.read_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_most_freq_reject_reason.pkl'))\n",
    "else:\n",
    "    most_freq_rejection_reason = prev_app.groupby('SK_ID_CURR').apply(lambda x: x.CODE_REJECT_REASON.value_counts().index.values[0])\n",
    "    most_freq_rejection_reason.to_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_most_freq_reject_reason.pkl'))\n",
    "\n",
    "data.loc[:, 'most_freq_rejection_reason'] = data.SK_ID_CURR.map(most_freq_rejection_reason)\n",
    "\n",
    "# median amount annuity\n",
    "median_annuity                = prev_app.groupby('SK_ID_CURR')['AMT_ANNUITY'].median().map(lambda x: np.log(x + 1))\n",
    "data.loc[:, 'median_annuity'] = data.SK_ID_CURR.map(median_annuity)\n",
    "\n",
    "# mean of past annuity to credit applications\n",
    "past_annuity_credit = (prev_app.AMT_ANNUITY / prev_app.AMT_CREDIT).replace([np.inf, -np.inf], np.nan)\n",
    "past_annuity_credit = past_annuity_credit.groupby(prev_app.SK_ID_CURR).mean()\n",
    "data.loc[:, 'past_annuity_to_credit'] = data.SK_ID_CURR.map(past_annuity_credit)\n",
    "\n",
    "# difference between current credit and mean applied amount in previous applications\n",
    "# mean_applied_amount = prev_app.groupby('SK_ID_CURR')['AMT_APPLICATION'].mean()\n",
    "# mean_applied_amount = data.SK_ID_CURR.map(mean_applied_amount)\n",
    "# data.loc[:, 'diff_applied_current_credit'] = mean_applied_amount - data.AMT_CREDIT\n",
    "\n",
    "# difference of down_payment * rate and annuity\n",
    "diff_dp_annuity = ((prev_app.AMT_DOWN_PAYMENT * prev_app.RATE_DOWN_PAYMENT) - prev_app.AMT_ANNUITY).replace([np.inf, -np.inf])\n",
    "diff_dp_annuity = diff_dp_annuity.groupby(prev_app.SK_ID_CURR).sum()\n",
    "data.loc[:, 'diff_dp_annuity'] = data.SK_ID_CURR.map(diff_dp_annuity)\n",
    "\n",
    "# mean of decision on last application\n",
    "mean_last_decision = prev_app.groupby('SK_ID_CURR')['DAYS_DECISION'].mean()\n",
    "data.loc[:, 'mean_last_decision'] = data.SK_ID_CURR.map(mean_last_decision)\n",
    "\n",
    "# mean of term of previous credit\n",
    "mean_prev_credit = prev_app.groupby('SK_ID_CURR')['CNT_PAYMENT'].mean()\n",
    "data.loc[:, 'mean_prev_credit'] = data.SK_ID_CURR.map(mean_prev_credit)\n",
    "\n",
    "\n",
    "# deviation in hour, weekday at which previous application process started\n",
    "dev_hour_process                = prev_app.groupby('SK_ID_CURR')['HOUR_APPR_PROCESS_START'].std()\n",
    "data.loc[:, 'dev_hour_process'] = data.SK_ID_CURR.map(dev_hour_process)\n",
    "\n",
    "dev_weekday_process                = prev_app.groupby('SK_ID_CURR')['WEEKDAY_APPR_PROCESS_START'].std()\n",
    "data.loc[:, 'dev_weekday_process'] = data.SK_ID_CURR.map(dev_weekday_process)\n",
    "\n",
    "# mean hour, weekday at which previous application process started\n",
    "dev_hour_process                 = prev_app.groupby('SK_ID_CURR')['HOUR_APPR_PROCESS_START'].mean()\n",
    "data.loc[:, 'mean_hour_process'] = data.SK_ID_CURR.map(dev_hour_process)\n",
    "\n",
    "dev_weekday_process                 = prev_app.groupby('SK_ID_CURR')['WEEKDAY_APPR_PROCESS_START'].mean()\n",
    "data.loc[:, 'mean_weekday_process'] = data.SK_ID_CURR.map(dev_weekday_process)\n",
    "\n",
    "# mean days before applicaiton was made\n",
    "prev_app_decision                = prev_app.groupby('SK_ID_CURR')['DAYS_DECISION'].mean()\n",
    "data.loc[:, 'prev_app_decision'] = data.SK_ID_CURR.map(prev_app_decision)\n",
    "\n",
    "# difference between termination of credit and day decision was made\n",
    "diff_termination_decision                = prev_app.DAYS_TERMINATION.replace({365243: np.nan}) - prev_app.DAYS_DECISION\n",
    "diff_termination_decision                = diff_termination_decision.groupby(prev_app.SK_ID_CURR).mean()\n",
    "data.loc[:, 'diff_termination_decision'] = data.SK_ID_CURR.map(diff_termination_decision)\n",
    "\n",
    "# ratio of amt annuity and amt goods price\n",
    "ratio_prev_annuity_goods                = (prev_app.AMT_ANNUITY / prev_app.AMT_GOODS_PRICE).replace([np.inf, -np.inf], np.nan)\n",
    "ratio_prev_annuity_goods                = ratio_prev_annuity_goods.groupby(prev_app.SK_ID_CURR).mean()\n",
    "data.loc[:, 'mean_prev_annuity_goods']  = data.SK_ID_CURR.map(ratio_prev_annuity_goods)\n",
    "\n",
    "# max of ratio of amt annuity to amt goods price\n",
    "ratio_prev_annuity_goods                = (prev_app.AMT_ANNUITY / prev_app.AMT_GOODS_PRICE).replace([np.inf, -np.inf], np.nan)\n",
    "ratio_prev_annuity_goods                = ratio_prev_annuity_goods.groupby(prev_app.SK_ID_CURR).max()\n",
    "data.loc[:, 'max_prev_annuity_goods'] = data.SK_ID_CURR.map(ratio_prev_annuity_goods)\n",
    "\n",
    "\n",
    "# max of ratio of amt annuity to amt_credit_sum\n",
    "ratio_prev_annuity_credit                = (prev_app.AMT_ANNUITY / prev_app.AMT_CREDIT).replace([np.inf, -np.inf], np.nan)\n",
    "ratio_prev_annuity_credit                = ratio_prev_annuity_goods.groupby(prev_app.SK_ID_CURR).max()\n",
    "data.loc[:, 'max_prev_annuity_credit']   = data.SK_ID_CURR.map(ratio_prev_annuity_credit)\n",
    "\n",
    "###############################################################################################################\n",
    "#                                 POS CASH                                                                    #\n",
    "###############################################################################################################\n",
    "data, cif_cols = get_agg_features(data, pos_cash, 'CNT_INSTALMENT_FUTURE', 'SK_ID_CURR')\n",
    "\n",
    "# mean of term of previous credits\n",
    "mean_term = pos_cash.groupby('SK_ID_CURR')['CNT_INSTALMENT'].mean()\n",
    "data.loc[:, 'mean_term'] = data.SK_ID_CURR.map(mean_term)\n",
    "\n",
    "# total number of installments\n",
    "total_installments                = pos_cash.CNT_INSTALMENT + pos_cash.CNT_INSTALMENT_FUTURE\n",
    "total_installments                = total_installments.groupby(pos_cash.SK_ID_CURR).sum()\n",
    "data.loc[:, 'total_installments'] = data.SK_ID_CURR.map(total_installments)\n",
    "\n",
    "# ratio of paid to unpaid number of installments\n",
    "ratio_paid_unpaid = (pos_cash.CNT_INSTALMENT_FUTURE / pos_cash.CNT_INSTALMENT).replace([np.inf, -np.inf], np.nan)\n",
    "ratio_paid_unpaid = ratio_paid_unpaid.groupby(pos_cash.SK_ID_CURR).mean()\n",
    "data.loc[:, 'ratio_paid_unpaid'] = data.SK_ID_CURR.map(ratio_paid_unpaid)\n",
    "\n",
    "##############################################################################################################\n",
    "#                                Credit Card Balance                                                         #\n",
    "##############################################################################################################\n",
    "\n",
    "# mean of amount balance during previous payments\n",
    "mean_amt_balance = credit_bal.groupby('SK_ID_CURR')['AMT_BALANCE'].mean()\n",
    "data.loc[:, 'mean_amt_balance'] = data.SK_ID_CURR.map(mean_amt_balance)\n",
    "\n",
    "# mean of actual credit limit\n",
    "mean_credit_limit = credit_bal.groupby('SK_ID_CURR')['AMT_CREDIT_LIMIT_ACTUAL'].mean()\n",
    "data.loc[:, 'mean_credit_limit'] = data.SK_ID_CURR.map(mean_credit_limit)\n",
    "\n",
    "# total paid installments on previous credit\n",
    "total_paid_installments = credit_bal.groupby('SK_ID_CURR')['CNT_INSTALMENT_MATURE_CUM'].sum()\n",
    "data.loc[:, 'total_paid_installments'] = data.SK_ID_CURR.map(total_paid_installments)\n",
    "\n",
    "# mean total drawings\n",
    "mean_total_drawings                = credit_bal.groupby('SK_ID_CURR')['AMT_DRAWINGS_CURRENT'].mean()\n",
    "data.loc[:, 'mean_total_drawings'] = data.SK_ID_CURR.map(mean_total_drawings)\n",
    "\n",
    "# sum of diff between balance and credit limit\n",
    "diff_bal_credit   = credit_bal.AMT_BALANCE - credit_bal.AMT_CREDIT_LIMIT_ACTUAL\n",
    "diff_bal_credit   = diff_bal_credit.groupby(credit_bal.SK_ID_CURR).sum()\n",
    "\n",
    "data.loc[:, 'diff_bal_credit'] = data.SK_ID_CURR.map(diff_bal_credit)\n",
    "\n",
    "# mean of ratio of balance and credit limit\n",
    "ratio_bal_credit = credit_bal.AMT_BALANCE / credit_bal.AMT_CREDIT_LIMIT_ACTUAL\n",
    "ratio_bal_credit = ratio_bal_credit.groupby(credit_bal.SK_ID_CURR).mean()\n",
    "\n",
    "data.loc[:, 'ratio_bal_credit'] = data.SK_ID_CURR.map(ratio_bal_credit)\n",
    "\n",
    "# aggregate features for MONTHS_BALANCE\n",
    "data, mb_cols = get_agg_features(data, credit_bal, 'MONTHS_BALANCE', 'SK_ID_CURR')\n",
    "\n",
    "\n",
    "# ratio of minimum installment on credit card with amount balance\n",
    "ratio_min_installment_balance                = (credit_bal.AMT_BALANCE / credit_bal.AMT_INST_MIN_REGULARITY).replace([np.inf, -np.inf], np.nan)\n",
    "ratio_min_installment_balance                = ratio_min_installment_balance.groupby(credit_bal.SK_ID_CURR).mean()\n",
    "data.loc[:, 'ratio_min_installment_balance'] = data.SK_ID_CURR.map(ratio_min_installment_balance)\n",
    "\n",
    "# difference of minimum installment on credit card with amount balance\n",
    "diff_min_installment_balance                = (credit_bal.AMT_BALANCE - credit_bal.AMT_INST_MIN_REGULARITY).replace([np.inf, -np.inf], np.nan)\n",
    "diff_min_installment_balance                = diff_min_installment_balance.groupby(credit_bal.SK_ID_CURR).mean().map(lambda x: np.log(x + 1))\n",
    "data.loc[:, 'diff_min_installment_balance'] = data.SK_ID_CURR.map(diff_min_installment_balance)\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "#                                  Installment Payments                                                       #\n",
    "###############################################################################################################\n",
    "\n",
    "# mean installment\n",
    "mean_installment                = installments.groupby('SK_ID_CURR')['AMT_INSTALMENT'].mean()\n",
    "data.loc[:, 'mean_installment'] = data.SK_ID_CURR.map(mean_installment)\n",
    "\n",
    "# mean payment against installment\n",
    "data, ap_cols               = get_agg_features(data, installments, 'AMT_PAYMENT', 'SK_ID_CURR')\n",
    "\n",
    "# difference between actual day of installment versus when it was supposed to be paid\n",
    "\n",
    "diff_actual_decided = -(installments.DAYS_ENTRY_PAYMENT - installments.DAYS_INSTALMENT)\n",
    "diff_actual_decided = diff_actual_decided.groupby(installments.SK_ID_CURR).mean()\n",
    "\n",
    "data.loc[:, 'diff_actual_decided'] = data.SK_ID_CURR.map(diff_actual_decided)\n",
    "\n",
    "# ratio of installment to be paid versus actual amount paid\n",
    "\n",
    "res = (installments.AMT_INSTALMENT / installments.AMT_PAYMENT).replace([np.inf, -np.inf], np.nan)\n",
    "res = res.groupby(installments.SK_ID_CURR).mean()\n",
    "\n",
    "data.loc[:, 'ratio_actual_decided_amount'] = data.SK_ID_CURR.map(res)\n",
    "\n",
    "###############################################################################################################\n",
    "#                                Previous and Current Application                                             #   \n",
    "###############################################################################################################\n",
    "\n",
    "# ratio of mean of amount credit sum from previous applications and current amount credit sum\n",
    "prev_amt_credit_mean = prev_app.groupby('SK_ID_CURR')['AMT_CREDIT'].mean()\n",
    "prev_amt_credit_mean = data.SK_ID_CURR.map(prev_amt_credit_mean)\n",
    "\n",
    "data.loc[:, 'ratio_prev_curr_credit'] = (data.AMT_CREDIT / prev_amt_credit_mean)\\\n",
    "                                             .replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "\n",
    "# diff (amt_annuity / amt_credit) current and previous application\n",
    "ratio_annuity_credit = (prev_app.AMT_ANNUITY / prev_app.AMT_CREDIT).replace([np.inf, -np.inf], np.nan)\n",
    "ratio_annuity_credit = ratio_annuity_credit.groupby(prev_app.SK_ID_CURR).mean()\n",
    "data.loc[:, 'diff_annuity_credit_curr_prev'] = data.ratio_annuity_credit - ratio_annuity_credit\n",
    "\n",
    "\n",
    "# diff (amt_goods_price / amt_credit_sum) current and previous application\n",
    "ratio_goods_credit = (prev_app.AMT_GOODS_PRICE / prev_app.AMT_CREDIT).replace([np.inf, -np.inf], np.nan)\n",
    "ratio_goods_credit = ratio_goods_credit.groupby(prev_app.SK_ID_CURR).mean()\n",
    "data.loc[:, 'diff_credit_goods_curr_prev'] = data.ratio_goods_credit - ratio_goods_credit\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "#                               Previous Application and Bureau                                               #\n",
    "###############################################################################################################\n",
    "\n",
    "\n",
    "# difference between day decision was made and remaining duration of CB Credit\n",
    "dcn = bureau.groupby('SK_ID_CURR')['DAYS_CREDIT_ENDDATE'].mean()\n",
    "dd  = prev_app.groupby('SK_ID_CURR')['DAYS_DECISION'].mean()\n",
    "data.loc[:, 'diff_decision_credit_end'] = data.SK_ID_CURR.map(dd - dcn)\n",
    "\n",
    "dcu = bureau.groupby('SK_ID_CURR')['DAYS_CREDIT_UPDATE'].mean() \n",
    "dd  = prev_app.groupby('SK_ID_CURR')['DAYS_DECISION'].mean()\n",
    "data.loc[:, 'diff_decision_update'] = data.SK_ID_CURR.map(dd - dcu)\n",
    "\n",
    "df  = bureau.groupby('SK_ID_CURR')['DAYS_ENDDATE_FACT'].mean() \n",
    "dd  = prev_app.groupby('SK_ID_CURR')['DAYS_DECISION'].mean()\n",
    "data.loc[:, 'diff_decision_fact'] = data.SK_ID_CURR.map(dd - df)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# delete all intermediatory variables\n",
    "del prev_num_loans, num_active_credits, bureau\n",
    "del mean_days_overdue, mean_days_credit_end\n",
    "del mean_max_amt_overdue, sum_num_times_prolonged\n",
    "del mean_cb_credit_annuity, std_cb_credit_annuity\n",
    "del num_diff_credits, mean_days_credit_update\n",
    "del mean_status, prev_bal, credit_history\n",
    "del num_prev_apps\n",
    "del prev_app, down_payment_to_application\n",
    "del mean_down_payment_rate, most_freq_rejection_reason\n",
    "del median_annuity\n",
    "del latest_credit, credit_duration\n",
    "del mean_total_amt_overdue, credit_times_duration\n",
    "del past_annuity_credit, mean_last_decision\n",
    "del credit_bal, mean_amt_balance, mean_credit_limit\n",
    "del total_paid_installments, mean_total_drawings\n",
    "del diff_bal_credit, diff_prev_curr_credit\n",
    "del diff1, diff2, diff, num_nulls_enddate\n",
    "del ratio_debt_total, ratio_min_installment_balance\n",
    "del diff_min_installment_balance\n",
    "del total_installments, prev_amt_credit_mean\n",
    "del dev_weekday_process, dev_hour_process\n",
    "del prev_app_decision, diff_termination_decision\n",
    "del ratio_prev_annuity_goods, dcn, dd, dcu, df\n",
    "del ratio_prev_annuity_credit, diff_actual_decided\n",
    "\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: CNT_CHILDREN\n",
      "Feature: num_nulls_enddate\n",
      "Feature: num_prev_apps\n"
     ]
    }
   ],
   "source": [
    "# replace feature values with frequency less 20 with -100\n",
    "for f in data.select_dtypes(include=['int8']).columns:\n",
    "    if data[f].nunique() > 10:        \n",
    "        low_freq_values = data[f].value_counts()\n",
    "        low_freq_values = low_freq_values[low_freq_values < 20].index.values\n",
    "        \n",
    "        if len(low_freq_values) > 0:\n",
    "            print('Feature: {}'.format(f))\n",
    "            data.loc[data[f].isin(low_freq_values), f] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amt_reqd_summary_summary         1.000000\n",
       "ratio_min_installment_balance    0.803803\n",
       "diff_min_installment_balance     0.713548\n",
       "ratio_bal_credit                 0.712010\n",
       "median_MONTHS_BALANCE_median     0.709315\n",
       "mean_amt_balance                 0.709315\n",
       "diff_bal_credit                  0.709315\n",
       "mean_MONTHS_BALANCE_mean         0.709315\n",
       "mean_credit_limit                0.709315\n",
       "max_MONTHS_BALANCE_amax          0.709315\n",
       "min_MONTHS_BALANCE_var           0.709315\n",
       "var_MONTHS_BALANCE_amin          0.709315\n",
       "sum_MONTHS_BALANCE_sum           0.709315\n",
       "mean_total_drawings              0.709315\n",
       "total_paid_installments          0.709315\n",
       "COMMONAREA_MODE                  0.697141\n",
       "COMMONAREA_MEDI                  0.697141\n",
       "COMMONAREA_AVG                   0.697141\n",
       "NONLIVINGAPARTMENTS_MEDI         0.692933\n",
       "NONLIVINGAPARTMENTS_AVG          0.692933\n",
       "NONLIVINGAPARTMENTS_MODE         0.692933\n",
       "LIVINGAPARTMENTS_MODE            0.682037\n",
       "LIVINGAPARTMENTS_MEDI            0.682037\n",
       "LIVINGAPARTMENTS_AVG             0.682037\n",
       "FLOORSMIN_MEDI                   0.676785\n",
       "FLOORSMIN_MODE                   0.676785\n",
       "FLOORSMIN_AVG                    0.676785\n",
       "YEARS_BUILD_AVG                  0.663306\n",
       "YEARS_BUILD_MEDI                 0.663306\n",
       "YEARS_BUILD_MODE                 0.663306\n",
       "                                   ...   \n",
       "WALLSMATERIAL_MODE               0.000000\n",
       "REG_REGION_NOT_WORK_REGION       0.000000\n",
       "FLAG_DOCUMENT_9                  0.000000\n",
       "REG_REGION_NOT_LIVE_REGION       0.000000\n",
       "FLAG_EMAIL                       0.000000\n",
       "FLAG_EMP_PHONE                   0.000000\n",
       "FLAG_MOBIL                       0.000000\n",
       "FLAG_OWN_CAR                     0.000000\n",
       "FLAG_OWN_REALTY                  0.000000\n",
       "FLAG_PHONE                       0.000000\n",
       "FLAG_WORK_PHONE                  0.000000\n",
       "FONDKAPREMONT_MODE               0.000000\n",
       "HOUR_APPR_PROCESS_START          0.000000\n",
       "HOUSETYPE_MODE                   0.000000\n",
       "LIVE_CITY_NOT_WORK_CITY          0.000000\n",
       "LIVE_REGION_NOT_WORK_REGION      0.000000\n",
       "NAME_CONTRACT_TYPE               0.000000\n",
       "NAME_EDUCATION_TYPE              0.000000\n",
       "NAME_HOUSING_TYPE                0.000000\n",
       "NAME_INCOME_TYPE                 0.000000\n",
       "NAME_TYPE_SUITE                  0.000000\n",
       "num_prev_apps                    0.000000\n",
       "OCCUPATION_TYPE                  0.000000\n",
       "ORGANIZATION_TYPE                0.000000\n",
       "REGION_POPULATION_RELATIVE       0.000000\n",
       "REGION_RATING_CLIENT             0.000000\n",
       "REGION_RATING_CLIENT_W_CITY      0.000000\n",
       "REG_CITY_NOT_LIVE_CITY           0.000000\n",
       "REG_CITY_NOT_WORK_CITY           0.000000\n",
       "NAME_FAMILY_STATUS               0.000000\n",
       "Length: 255, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.isnull().sum() / len(data)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unpack to train and test\n",
    "tr = data.iloc[:ntrain]\n",
    "te = data.iloc[ntrain:]\n",
    "\n",
    "del data\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLS_TO_REMOVE = [\n",
    "                  'FLAG_DOCUMENT_21',\n",
    "                  'FLAG_DOCUMENT_4',\n",
    "                  'FLAG_MOBIL',\n",
    "                  'FLAG_DOCUMENT_2',\n",
    "                  'FLAG_DOCUMENT_20',\n",
    "                  'FLAG_DOCUMENT_9',\n",
    "                  'FLAG_DOCUMENT_17',\n",
    "                  'FLAG_DOCUMENT_19',\n",
    "                  'FLAG_DOCUMENT_5',\n",
    "                  'FLAG_CONT_MOBILE',\n",
    "                  'FLAG_DOCUMENT_10',\n",
    "                  'HOUSETYPE_MODE',\n",
    "                  'FLAG_DOCUMENT_12',\n",
    "                  'FLAG_DOCUMENT_7',\n",
    "                  'FLAG_DOCUMENT_11',\n",
    "                  'AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "                  'LIVE_REGION_NOT_WORK_REGION',\n",
    "                  'AMT_REQ_CREDIT_BUREAU_DAY',\n",
    "                  'FLAG_DOCUMENT_15',\n",
    "                  'EMERGENCYSTATE_MODE',\n",
    "                  'REG_REGION_NOT_LIVE_REGION',\n",
    "                  'SK_ID_CURR',\n",
    "                  'FLAG_EMP_PHONE',\n",
    "                  'REG_REGION_NOT_WORK_REGION',\n",
    "                  'FLAG_DOCUMENT_14',\n",
    "                  'FLAG_DOCUMENT_6',\n",
    "                  'TARGET'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [f for f in tr.columns if f not in COLS_TO_REMOVE]\n",
    "\n",
    "Xtr  = tr.loc[:, features]\n",
    "ytr  = tr.loc[:, 'TARGET']\n",
    "\n",
    "Xval = te.loc[:, features]\n",
    "# yval = te.loc[:, 'TARGET'] # only execute during validation phase\n",
    "\n",
    "del tr, te\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features used in the model are: 228\n"
     ]
    }
   ],
   "source": [
    "print('Number of features used in the model are: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[20]\ttrain's auc: 0.737369\tval's auc: 0.726536\n",
      "[40]\ttrain's auc: 0.744584\tval's auc: 0.730858\n",
      "[60]\ttrain's auc: 0.752315\tval's auc: 0.736088\n",
      "[80]\ttrain's auc: 0.758626\tval's auc: 0.7406\n",
      "[100]\ttrain's auc: 0.764957\tval's auc: 0.745562\n",
      "[120]\ttrain's auc: 0.771259\tval's auc: 0.749946\n",
      "[140]\ttrain's auc: 0.778105\tval's auc: 0.754607\n",
      "[160]\ttrain's auc: 0.784398\tval's auc: 0.758657\n",
      "[180]\ttrain's auc: 0.790219\tval's auc: 0.762379\n",
      "[200]\ttrain's auc: 0.795905\tval's auc: 0.765977\n",
      "[220]\ttrain's auc: 0.801274\tval's auc: 0.769291\n",
      "[240]\ttrain's auc: 0.805945\tval's auc: 0.771581\n",
      "[260]\ttrain's auc: 0.810492\tval's auc: 0.773897\n",
      "[280]\ttrain's auc: 0.814734\tval's auc: 0.77548\n",
      "[300]\ttrain's auc: 0.818672\tval's auc: 0.776952\n",
      "[320]\ttrain's auc: 0.822331\tval's auc: 0.778151\n",
      "[340]\ttrain's auc: 0.825982\tval's auc: 0.779214\n",
      "[360]\ttrain's auc: 0.82952\tval's auc: 0.780266\n",
      "[380]\ttrain's auc: 0.832878\tval's auc: 0.781104\n",
      "[400]\ttrain's auc: 0.836236\tval's auc: 0.781802\n",
      "[420]\ttrain's auc: 0.839409\tval's auc: 0.782333\n",
      "[440]\ttrain's auc: 0.842661\tval's auc: 0.78302\n",
      "[460]\ttrain's auc: 0.8456\tval's auc: 0.783491\n",
      "[480]\ttrain's auc: 0.848569\tval's auc: 0.783889\n",
      "[500]\ttrain's auc: 0.851587\tval's auc: 0.784449\n",
      "[520]\ttrain's auc: 0.854358\tval's auc: 0.784861\n",
      "[540]\ttrain's auc: 0.85703\tval's auc: 0.785227\n",
      "[560]\ttrain's auc: 0.859733\tval's auc: 0.785534\n",
      "[580]\ttrain's auc: 0.862419\tval's auc: 0.785786\n",
      "[600]\ttrain's auc: 0.864966\tval's auc: 0.785942\n",
      "[620]\ttrain's auc: 0.867358\tval's auc: 0.786078\n",
      "[640]\ttrain's auc: 0.869843\tval's auc: 0.786228\n",
      "[660]\ttrain's auc: 0.872155\tval's auc: 0.786388\n",
      "[680]\ttrain's auc: 0.874453\tval's auc: 0.786546\n",
      "[700]\ttrain's auc: 0.876571\tval's auc: 0.786638\n",
      "[720]\ttrain's auc: 0.87876\tval's auc: 0.786759\n",
      "[740]\ttrain's auc: 0.881001\tval's auc: 0.786831\n",
      "[760]\ttrain's auc: 0.883091\tval's auc: 0.786939\n",
      "[780]\ttrain's auc: 0.885144\tval's auc: 0.786978\n",
      "[800]\ttrain's auc: 0.887134\tval's auc: 0.786989\n",
      "[820]\ttrain's auc: 0.889107\tval's auc: 0.786991\n",
      "[840]\ttrain's auc: 0.891037\tval's auc: 0.787031\n",
      "[860]\ttrain's auc: 0.892941\tval's auc: 0.787008\n",
      "[880]\ttrain's auc: 0.894838\tval's auc: 0.787024\n",
      "[900]\ttrain's auc: 0.896563\tval's auc: 0.787077\n",
      "[920]\ttrain's auc: 0.898395\tval's auc: 0.787133\n",
      "[940]\ttrain's auc: 0.900115\tval's auc: 0.787119\n",
      "[960]\ttrain's auc: 0.90183\tval's auc: 0.787128\n",
      "[980]\ttrain's auc: 0.903516\tval's auc: 0.787134\n",
      "[1000]\ttrain's auc: 0.905148\tval's auc: 0.787165\n",
      "[1020]\ttrain's auc: 0.906771\tval's auc: 0.787201\n",
      "[1040]\ttrain's auc: 0.908364\tval's auc: 0.787193\n",
      "[1060]\ttrain's auc: 0.9099\tval's auc: 0.787248\n",
      "[1080]\ttrain's auc: 0.91146\tval's auc: 0.787265\n",
      "[1100]\ttrain's auc: 0.912904\tval's auc: 0.787218\n",
      "[1120]\ttrain's auc: 0.91433\tval's auc: 0.787177\n",
      "[1140]\ttrain's auc: 0.915825\tval's auc: 0.787136\n",
      "[1160]\ttrain's auc: 0.917237\tval's auc: 0.787129\n",
      "Early stopping, best iteration is:\n",
      "[1068]\ttrain's auc: 0.910518\tval's auc: 0.787271\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': .02,\n",
    "    'metric': 'auc',\n",
    "    'min_data_in_leaf': 100,\n",
    "    'num_leaves': 64,\n",
    "    'feature_fraction': .65,\n",
    "    'bagging_fraction': .8,\n",
    "    'lambda_l1': 5,\n",
    "    'lambda_l2': 5,\n",
    "    'min_child_weight': 1.,\n",
    "    'nthread': 4\n",
    "}\n",
    "\n",
    "ltrain = lgb.Dataset(Xtr, ytr, feature_name=features)\n",
    "lval   = lgb.Dataset(Xval, yval, feature_name=features)\n",
    "\n",
    "valid_sets  = [ltrain, lval]\n",
    "valid_names = ['train', 'val']\n",
    "\n",
    "num_boost_round       = 5000\n",
    "early_stopping_rounds = 100\n",
    "\n",
    "m = lgb.train(params, \n",
    "              ltrain, \n",
    "              num_boost_round, \n",
    "              valid_sets=valid_sets, \n",
    "              valid_names=valid_names, \n",
    "              early_stopping_rounds=early_stopping_rounds, \n",
    "              verbose_eval=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[1068]\ttrain's auc: 0.910518\tval's auc: 0.787271`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>ratio_annuity_credit</td>\n",
       "      <td>1213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>sum_AMT_PAYMENT_sum</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>EXT_SOURCE_SUM</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DAYS_BIRTH</td>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>ratio_debt_total</td>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>EXT_SOURCE_2</td>\n",
       "      <td>909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>diff_actual_decided</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>EXT_SOURCE_3</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>ratio_paid_unpaid</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>ratio_actual_decided_amount</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>ratio_goods_credit</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>max_DAYS_CREDIT_amax</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>ratio_annuity_score_1</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>var_AMT_PAYMENT_amin</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>mean_prev_credit</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>min_CNT_INSTALMENT_FUTURE_var</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>EXT_SOURCE_1</td>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>dev_hour_process</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>ratio_annuity_score_3</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>ratio_annuity_score_2</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>age_plus_employed</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>max_AMT_PAYMENT_amax</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>mean_last_decision</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>diff_termination_decision</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>max_prev_annuity_goods</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>diff_dp_annuity</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>median_AMT_PAYMENT_median</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>mean_diff_ended_curr_credit</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>mean_hour_process</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>dev_weekday_process</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>num_diff_credits</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>FLAG_PHONE</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>NONLIVINGAPARTMENTS_AVG</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CNT_CHILDREN</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>WALLSMATERIAL_MODE</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>var_CNT_INSTALMENT_FUTURE_amin</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>FLOORSMAX_MEDI</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FLAG_DOCUMENT_18</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>NAME_TYPE_SUITE</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>FLOORSMIN_MODE</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMT_REQ_CREDIT_BUREAU_MON</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>REG_CITY_NOT_WORK_CITY</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ELEVATORS_MEDI</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ELEVATORS_MODE</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FLAG_OWN_REALTY</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMT_REQ_CREDIT_BUREAU_WEEK</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>NAME_CONTRACT_TYPE</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>NONLIVINGAPARTMENTS_MODE</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>FLAG_OWN_CAR</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>LIVE_CITY_NOT_WORK_CITY</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FLOORSMAX_MODE</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>max_MONTHS_BALANCE_amax</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>FLAG_DOCUMENT_13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>FLAG_DOCUMENT_8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FLAG_EMAIL</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>FONDKAPREMONT_MODE</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>FLAG_DOCUMENT_16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>sum_num_times_prolonged</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>amt_reqd_summary_summary</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>mean_credit_days_overdue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           features   imp\n",
       "113            ratio_annuity_credit  1213\n",
       "219             sum_AMT_PAYMENT_sum  1041\n",
       "96                   EXT_SOURCE_SUM   970\n",
       "20                       DAYS_BIRTH   966\n",
       "152                ratio_debt_total   963\n",
       "34                     EXT_SOURCE_2   909\n",
       "220             diff_actual_decided   853\n",
       "35                     EXT_SOURCE_3   845\n",
       "198               ratio_paid_unpaid   824\n",
       "221     ratio_actual_decided_amount   726\n",
       "111              ratio_goods_credit   712\n",
       "134            max_DAYS_CREDIT_amax   710\n",
       "117           ratio_annuity_score_1   699\n",
       "218            var_AMT_PAYMENT_amin   693\n",
       "180                mean_prev_credit   689\n",
       "193   min_CNT_INSTALMENT_FUTURE_var   679\n",
       "33                     EXT_SOURCE_1   674\n",
       "181                dev_hour_process   670\n",
       "119           ratio_annuity_score_3   655\n",
       "118           ratio_annuity_score_2   635\n",
       "106               age_plus_employed   634\n",
       "216            max_AMT_PAYMENT_amax   607\n",
       "179              mean_last_decision   607\n",
       "186       diff_termination_decision   598\n",
       "188          max_prev_annuity_goods   597\n",
       "178                 diff_dp_annuity   586\n",
       "215       median_AMT_PAYMENT_median   577\n",
       "148     mean_diff_ended_curr_credit   571\n",
       "183               mean_hour_process   566\n",
       "182             dev_weekday_process   553\n",
       "..                              ...   ...\n",
       "162                num_diff_credits    43\n",
       "44                       FLAG_PHONE    43\n",
       "70          NONLIVINGAPARTMENTS_AVG    42\n",
       "14                     CNT_CHILDREN    38\n",
       "87               WALLSMATERIAL_MODE    37\n",
       "194  var_CNT_INSTALMENT_FUTURE_amin    37\n",
       "47                   FLOORSMAX_MEDI    37\n",
       "38                 FLAG_DOCUMENT_18    36\n",
       "69                  NAME_TYPE_SUITE    31\n",
       "51                   FLOORSMIN_MODE    29\n",
       "4         AMT_REQ_CREDIT_BUREAU_MON    23\n",
       "85           REG_CITY_NOT_WORK_CITY    23\n",
       "28                   ELEVATORS_MEDI    22\n",
       "29                   ELEVATORS_MODE    21\n",
       "43                  FLAG_OWN_REALTY    20\n",
       "6        AMT_REQ_CREDIT_BUREAU_WEEK    20\n",
       "64               NAME_CONTRACT_TYPE    20\n",
       "72         NONLIVINGAPARTMENTS_MODE    19\n",
       "42                     FLAG_OWN_CAR    19\n",
       "57          LIVE_CITY_NOT_WORK_CITY    18\n",
       "48                   FLOORSMAX_MODE    15\n",
       "207         max_MONTHS_BALANCE_amax    14\n",
       "36                 FLAG_DOCUMENT_13    13\n",
       "40                  FLAG_DOCUMENT_8    12\n",
       "41                       FLAG_EMAIL     8\n",
       "52               FONDKAPREMONT_MODE     6\n",
       "37                 FLAG_DOCUMENT_16     4\n",
       "159         sum_num_times_prolonged     1\n",
       "131        amt_reqd_summary_summary     0\n",
       "155        mean_credit_days_overdue     0\n",
       "\n",
       "[228 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature importance df\n",
    "feat_imp = pd.DataFrame({'features': features,\n",
    "                         'imp': m.feature_importance()\n",
    "                        })\n",
    "\n",
    "feat_imp.sort_values(by='imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>ratio_actual_decided_amount</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        features  imp\n",
       "219  ratio_actual_decided_amount  422"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp[feat_imp.features == 'ratio_actual_decided_amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOF Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.5 s, sys: 156 ms, total: 17.7 s\n",
      "Wall time: 5.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "HOLDOUT_SCORE  = 0.787271 \n",
    "\n",
    "oof_preds = m.predict(Xval)\n",
    "joblib.dump(oof_preds, os.path.join(basepath, f'data/oof_sub/{MODEL_PRESET}_{HOLDOUT_SCORE}_preds.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30min 1s, sys: 2.88 s, total: 30min 4s\n",
      "Wall time: 7min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': (.02 / 1.2),\n",
    "    'metric': 'auc',\n",
    "    'min_data_in_leaf': 100,\n",
    "    'num_leaves': 64,\n",
    "    'feature_fraction': .65,\n",
    "    'bagging_fraction': .8,\n",
    "    'lambda_l1': 5,\n",
    "    'lambda_l2': 5,\n",
    "    'min_child_weight': 1.,\n",
    "    'nthread': 4\n",
    "}\n",
    "\n",
    "BEST_ITERATION  = 1068\n",
    "\n",
    "num_boost_round = int(BEST_ITERATION * 1.2)\n",
    "ltrain          = lgb.Dataset(Xtr, ytr, feature_name=features)\n",
    "\n",
    "m           = lgb.train(params, ltrain, num_boost_round)\n",
    "final_preds = m.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOLDOUT_SCORE  = 0.787271\n",
    "\n",
    "sub_identifier = \"%s-%s-%.5f\" % (datetime.now().strftime('%Y%m%d-%H%M'), MODEL_PRESET, HOLDOUT_SCORE)\n",
    "\n",
    "sub           = pd.read_csv('../data/raw/sample_submission.csv.zip')\n",
    "sub['TARGET'] = final_preds\n",
    "\n",
    "sub.to_csv(os.path.join(basepath, 'submissions/%s.csv'%(sub_identifier)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
