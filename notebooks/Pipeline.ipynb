{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries have been loaded\n"
     ]
    }
   ],
   "source": [
    "__imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Ideas\n",
    "\n",
    "- From previous application we can figure out the max of days decision which would represent relative to current application when was the decision about previous application made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Additional Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import lightgbm as lgb\n",
    "from features import woe\n",
    "\n",
    "basepath   = os.path.expanduser('../')\n",
    "\n",
    "# train and validation fold\n",
    "TRAIN_PATH = os.path.join(basepath, 'data/processed/application_train_fold.feather')\n",
    "TEST_PATH  = os.path.join(basepath, 'data/processed/application_val_fold.feather')\n",
    "\n",
    "# full training\n",
    "TRAIN_PATH = os.path.join(basepath, 'data/processed/application_train.feather')\n",
    "TEST_PATH  = os.path.join(basepath, 'data/processed/application_test.feather')\n",
    "\n",
    "# MODEL PRESET\n",
    "MODEL_PRESET   = 'M26'\n",
    "\n",
    "# DATASET PREFIX\n",
    "# DATASET_PREFIX = 'tr'\n",
    "DATASET_PREFIX  = 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 714 ms, sys: 1.81 s, total: 2.52 s\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tr = pd.read_feather(f'{TRAIN_PATH}')\n",
    "te = pd.read_feather(f'{TEST_PATH}')\n",
    "\n",
    "# Application data from previous loans\n",
    "bureau       = pd.read_feather(os.path.join(basepath, 'data/processed/bureau.feather'))\n",
    "bureau_bal   = pd.read_feather(os.path.join(basepath, 'data/processed/bureau_balance.feather'))\n",
    "prev_app     = pd.read_pickle(os.path.join(basepath, 'data/processed/prev_app.pkl'))\n",
    "pos_cash     = pd.read_pickle(os.path.join(basepath, 'data/processed/pos_cash.pkl'))\n",
    "credit_bal   = pd.read_pickle(os.path.join(basepath, 'data/processed/credit_card_balance.pkl'))\n",
    "installments = pd.read_pickle(os.path.join(basepath, 'data/processed/installments_payments.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concat training and test set\n",
    "data   = pd.concat((tr, te))\n",
    "ntrain = len(tr) \n",
    "\n",
    "del tr, te\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_agg_features(data, gp, f, on):\n",
    "    agg         = gp.groupby(on)[f]\\\n",
    "                        .agg({np.mean, np.median, np.max, np.min, np.var, np.sum}).fillna(-1)\n",
    "    \n",
    "    cols        = [f'{f}_{c}' for i, c in enumerate(agg.columns)]\n",
    "    agg.columns = cols\n",
    "    agg         = agg.reset_index()\n",
    "    data        = data.merge(agg, on=on, how='left')\n",
    "    \n",
    "    del agg\n",
    "    gc.collect();\n",
    "    \n",
    "    return data, cols    \n",
    "\n",
    "def log_features(data, features):\n",
    "    for f in features:\n",
    "        data.loc[:, f] = data[f].map(lambda x: np.log(x + 1))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# deviation in three external scores\n",
    "data.loc[:, 'EXT_SOURCE_DEV']  = data.loc[:, ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].apply(np.std, axis=1)\n",
    "\n",
    "# sum of external scores\n",
    "data.loc[:, 'EXT_SOURCE_SUM'] = data['EXT_SOURCE_1'].fillna(0) + data['EXT_SOURCE_2'].fillna(0) + data['EXT_SOURCE_3'].fillna(0)\n",
    "\n",
    "# mean of external scores\n",
    "data.loc[:, 'MEAN_EXTERNAL_SCORE'] = (data['EXT_SOURCE_1'].fillna(0) + data['EXT_SOURCE_2'].fillna(0) + data['EXT_SOURCE_3'].fillna(0)) / 3\n",
    "\n",
    "# number of null values in an application\n",
    "data.loc[:, 'num_nulls'] = data.isnull().sum(axis=1)\n",
    "\n",
    "# feature interactions\n",
    "data.loc[:, 'EXT_3_1'] = data.loc[:, 'EXT_SOURCE_3'] / data.loc[:, 'EXT_SOURCE_1']\n",
    "data.loc[:, 'EXT_3_2'] = data.loc[:, 'EXT_SOURCE_3'] / data.loc[:, 'EXT_SOURCE_2']\n",
    "data.loc[:, 'EXT_2_1'] = data.loc[:, 'EXT_SOURCE_2'] / data.loc[:, 'EXT_SOURCE_1']\n",
    "\n",
    "# relationship between amount credit and total income\n",
    "data.loc[:, 'ratio_credit_income'] = data.loc[:, 'AMT_CREDIT'] / data.loc[:, 'AMT_INCOME_TOTAL']\n",
    "\n",
    "# relationship between annual amount to be paid and income\n",
    "data.loc[:, 'ratio_annuity_income'] = data.loc[:, 'AMT_ANNUITY'] / data.loc[:, 'AMT_INCOME_TOTAL']\n",
    "\n",
    "# relationship between amount annuity and age\n",
    "data.loc[:, 'ratio_annuity_age'] = data.loc[:, 'AMT_ANNUITY'] / (-data.loc[:, 'DAYS_BIRTH'] / 365)\n",
    "\n",
    "# number of missing values in an application\n",
    "data.loc[:, 'num_missing_values'] = data.loc[:, data.columns.drop('TARGET')].isnull().sum(axis=1).values\n",
    "\n",
    "# feature interaction between age and days employed\n",
    "data.loc[:, 'age_plus_employed']  = data.loc[:, 'DAYS_BIRTH'] + data.loc[:, 'DAYS_EMPLOYED']\n",
    "data.loc[:, 'ratio_age_employed'] = (data.DAYS_EMPLOYED) / (data.DAYS_BIRTH)\n",
    "\n",
    "# ratio of value of goods against which loan is given to total income\n",
    "data.loc[:, 'ratio_goods_income'] = data.loc[:, 'AMT_GOODS_PRICE'] / data.loc[:, 'AMT_INCOME_TOTAL']\n",
    "\n",
    "# feature interaction between value of goods against which loan is given to annual loan amount to be paid\n",
    "data.loc[:, 'ratio_goods_annuity'] = data.loc[:, 'AMT_GOODS_PRICE'] / data.loc[:, 'AMT_ANNUITY']\n",
    "data.loc[:, 'mult_goods_annuity']  = data.loc[:, 'AMT_GOODS_PRICE'] * data.loc[:, 'AMT_ANNUITY']\n",
    "\n",
    "# feature interaction value of goods and amount credit\n",
    "data.loc[:, 'ratio_goods_credit'] = (data.loc[:, 'AMT_GOODS_PRICE'] / data.loc[:, 'AMT_CREDIT']).replace([np.inf, -np.inf], np.nan)\n",
    "data.loc[:, 'mult_goods_credit']  = (data.loc[:, 'AMT_GOODS_PRICE'] * data.loc[:, 'AMT_CREDIT']).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# feature interaction between annuity and amount credit\n",
    "data.loc[:, 'ratio_annuity_credit'] = data.loc[:, 'AMT_ANNUITY'] / data.loc[:, 'AMT_CREDIT'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# feature interaction between amount credit and age\n",
    "data.loc[:, 'ratio_credit_age'] = data.AMT_CREDIT / (-data.DAYS_BIRTH / 365)\n",
    "\n",
    "# feature interaction between amount credit and days before application id was changed\n",
    "data.loc[:, 'ratio_credit_id_change'] = (data.AMT_CREDIT / -data.DAYS_ID_PUBLISH).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# feature interaction between days id publish and age\n",
    "data.loc[:, 'ratio_id_change_age'] = (data.DAYS_ID_PUBLISH / (-data.DAYS_BIRTH / 365))\n",
    "\n",
    "# ratio of annuity and external score\n",
    "data.loc[:, 'ratio_annuity_score_1'] = (data.loc[:, 'AMT_ANNUITY'] / data.loc[:, 'EXT_SOURCE_1']).replace([np.inf, -np.inf], np.nan)\n",
    "data.loc[:, 'ratio_annuity_score_2'] = (data.loc[:, 'AMT_ANNUITY'] / data.loc[:, 'EXT_SOURCE_2']).replace([np.inf, -np.inf], np.nan)\n",
    "data.loc[:, 'ratio_annuity_score_3'] = (data.loc[:, 'AMT_ANNUITY'] / data.loc[:, 'EXT_SOURCE_3']).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# ratio of annuity, credit multiplied by external scores\n",
    "data.loc[:, 'ratio_credit_annuity_score_1'] = ((data.loc[:, 'AMT_ANNUITY'] / data.loc[:, 'AMT_CREDIT']) * data.loc[:, 'EXT_SOURCE_1']).replace([np.inf, -np.inf], np.nan)\n",
    "data.loc[:, 'ratio_credit_annuity_score_2'] = ((data.loc[:, 'AMT_ANNUITY'] / data.loc[:, 'AMT_CREDIT']) * data.loc[:, 'EXT_SOURCE_2']).replace([np.inf, -np.inf], np.nan)\n",
    "data.loc[:, 'ratio_credit_annuity_score_3'] = ((data.loc[:, 'AMT_ANNUITY'] / data.loc[:, 'AMT_CREDIT']) * data.loc[:, 'EXT_SOURCE_3']).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "\n",
    "# ratio of owner's car age with his age\n",
    "data.loc[:, 'ratio_car_person_age'] = (data.OWN_CAR_AGE / -data.DAYS_BIRTH)\n",
    "\n",
    "# difference credit and income\n",
    "data.loc[:, 'diff_credit_income'] = data.AMT_CREDIT - data.AMT_INCOME_TOTAL\n",
    "\n",
    "# difference income total and annuity\n",
    "data.loc[:, 'diff_income_annuity']  = data.AMT_ANNUITY - data.AMT_INCOME_TOTAL\n",
    "\n",
    "# difference credit and goods price\n",
    "data.loc[:, 'diff_credit_goods'] = data.AMT_CREDIT - data.AMT_GOODS_PRICE\n",
    "\n",
    "# max, mean, std of featur groups related to days before any document was modified or changed\n",
    "if os.path.exists(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_max_doc_modified.pkl')):\n",
    "    data.loc[:, 'max_document_modified'] = pd.read_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_max_doc_modified.pkl'))\n",
    "else:\n",
    "    max_document_modified = data.loc[:, ['DAYS_REGISTRATION',\n",
    "                                         'DAYS_ID_PUBLISH',\n",
    "                                         'DAYS_LAST_PHONE_CHANGE'\n",
    "                                        ]].apply(np.max, axis=1)\n",
    "    \n",
    "    max_document_modified.to_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_max_doc_modified.pkl'))\n",
    "    data.loc[:, 'max_document_modified'] = max_document_modified\n",
    "    \n",
    "    del max_document_modified\n",
    "    gc.collect();\n",
    "    \n",
    "if os.path.exists(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_mean_doc_modified.pkl')):\n",
    "    data.loc[:, 'mean_document_modified'] = pd.read_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_mean_doc_modified.pkl'))\n",
    "else:\n",
    "    mean_document_modified = data.loc[:, ['DAYS_REGISTRATION',\n",
    "                                         'DAYS_ID_PUBLISH',\n",
    "                                         'DAYS_LAST_PHONE_CHANGE'\n",
    "                                        ]].apply(np.mean, axis=1)\n",
    "    \n",
    "    mean_document_modified.to_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_mean_doc_modified.pkl'))\n",
    "    data.loc[:, 'mean_document_modified'] = mean_document_modified\n",
    "    \n",
    "    del mean_document_modified\n",
    "    gc.collect();\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_std_doc_modified.pkl')):\n",
    "    data.loc[:, 'std_document_modified'] = pd.read_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_std_doc_modified.pkl'))\n",
    "else:\n",
    "    std_document_modified = data.loc[:, ['DAYS_REGISTRATION',\n",
    "                                         'DAYS_ID_PUBLISH',\n",
    "                                         'DAYS_LAST_PHONE_CHANGE'\n",
    "                                        ]].apply(np.std, axis=1)\n",
    "    \n",
    "    std_document_modified.to_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_std_doc_modified.pkl'))\n",
    "    data.loc[:, 'std_document_modified'] = std_document_modified\n",
    "    \n",
    "    del std_document_modified\n",
    "    gc.collect();\n",
    "    \n",
    "\n",
    "# combine feature groups\n",
    "if os.path.exists(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_flag_document.pkl')):\n",
    "    data.loc[:, 'flag_document_summary'] = pd.read_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_flag_document.pkl'))\n",
    "else:\n",
    "    flag_document_summary = data.loc[:, [f for f in data.columns if 'FLAG' in f]].apply(np.sum, axis=1)\n",
    "    data.loc[:, 'flag_document_summary'] = flag_document_summary\n",
    "    \n",
    "    flag_document_summary.to_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_flag_document.pkl'))\n",
    "    \n",
    "    del flag_document_summary\n",
    "    gc.collect();\n",
    "    \n",
    "\n",
    "if os.path.exists(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_amt_reqd_credit.pkl')):\n",
    "    data.loc[:, 'amt_reqd_summary'] = pd.read_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_amt_reqd_credit.pkl'))\n",
    "else:\n",
    "    amt_reqd_credit_summary         = data.loc[:, [f for f in data.columns if 'AMT_REQ_CREDIT' in f]].apply(np.sum, axis=1)\n",
    "    data.loc[:, 'amt_reqd_summary'] = amt_reqd_credit_summary\n",
    "    \n",
    "    amt_reqd_credit_summary.to_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_amt_reqd_credit.pkl'))\n",
    "    \n",
    "    del amt_reqd_credit_summary\n",
    "    gc.collect();\n",
    "\n",
    "    \n",
    "##########################################################################################################\n",
    "#                            BUREAU                                                                      #\n",
    "##########################################################################################################\n",
    "\n",
    "# number of previous loans for a particular user\n",
    "prev_num_loans = bureau.groupby('SK_ID_CURR').size()\n",
    "\n",
    "# number of previous active credits\n",
    "num_active_credits = bureau.groupby('SK_ID_CURR')['CREDIT_ACTIVE'].sum()\n",
    "\n",
    "# aggregation features\n",
    "data, dc_cols  = get_agg_features(data, bureau, 'DAYS_CREDIT', 'SK_ID_CURR')\n",
    "data, acm_cols = get_agg_features(data, bureau, 'AMT_CREDIT_SUM', 'SK_ID_CURR')\n",
    "\n",
    "# logarithm of features\n",
    "data  = log_features(data, acm_cols)\n",
    "\n",
    "# mean number of days overdue on any previous credit\n",
    "mean_days_overdue = bureau.groupby('SK_ID_CURR')['CREDIT_DAY_OVERDUE'].mean()\n",
    "\n",
    "# mean number of days of CB credit at the time of application\n",
    "mean_days_credit_end = bureau.groupby('SK_ID_CURR')['DAYS_CREDIT_ENDDATE'].mean()\n",
    "\n",
    "# mean of maximum amount overdue on any credit line\n",
    "mean_max_amt_overdue = bureau.groupby('SK_ID_CURR')['AMT_CREDIT_MAX_OVERDUE'].mean().map(lambda x: np.log(x + 1))\n",
    "\n",
    "# mean of total amount overdue on any credit line\n",
    "mean_total_amt_overdue = bureau.groupby('SK_ID_CURR')['AMT_CREDIT_SUM_OVERDUE'].mean().map(lambda x: np.log(x + 1))\n",
    "\n",
    "# sum of num times credit was prolonged\n",
    "sum_num_times_prolonged = bureau.groupby('SK_ID_CURR')['CNT_CREDIT_PROLONG'].sum()\n",
    "\n",
    "# number of different types of credit taken from CREDIT BUREAU\n",
    "num_diff_credits = bureau.groupby('SK_ID_CURR')['CREDIT_TYPE'].nunique()\n",
    "\n",
    "# mean number of days of last credit update\n",
    "mean_days_credit_update = bureau.groupby('SK_ID_CURR')['DAYS_CREDIT_UPDATE'].mean()    \n",
    "    \n",
    "# summary of amount of annuity of credit bureau loans\n",
    "mean_cb_credit_annuity = bureau.groupby('SK_ID_CURR')['AMT_ANNUITY'].mean().map(lambda x: np.log(x + 1))\n",
    "std_cb_credit_annuity  = bureau.groupby('SK_ID_CURR')['AMT_ANNUITY'].std().map(lambda x: np.log(x + 1))\n",
    "\n",
    "# latest application reported to Home Credit\n",
    "latest_credit = bureau.groupby('SK_ID_CURR')['DAYS_CREDIT'].max()\n",
    "data.loc[:, 'latest_credit'] = data.SK_ID_CURR.map(latest_credit)\n",
    "\n",
    "# day before current application date\n",
    "credit_duration = (bureau.DAYS_CREDIT_ENDDATE - bureau.DAYS_CREDIT).map(np.abs).groupby(bureau.SK_ID_CURR).mean()\n",
    "data.loc[:, 'credit_duration'] = data.SK_ID_CURR.map(credit_duration).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# deviation in difference between remaining duration of credit and how long before we applied for this credit\n",
    "diff_prev_curr_credit = bureau.DAYS_CREDIT_ENDDATE.fillna(0) - bureau.DAYS_CREDIT.fillna(0)\n",
    "diff_prev_curr_credit = diff_prev_curr_credit.groupby(bureau.SK_ID_CURR).std()\n",
    "data.loc[:, 'std_diff_prev_curr_credit'] = data.SK_ID_CURR.map(diff_prev_curr_credit)\n",
    "\n",
    "\n",
    "# mean of difference between remaining duration of credit and how long before we applied for this credit\n",
    "diff_prev_curr_credit = bureau.DAYS_CREDIT_ENDDATE - bureau.DAYS_CREDIT\n",
    "diff_prev_curr_credit = diff_prev_curr_credit.groupby(bureau.SK_ID_CURR).mean()\n",
    "data.loc[:, 'mean_diff_prev_curr_credit'] = data.SK_ID_CURR.map(diff_prev_curr_credit)\n",
    "\n",
    "# mean of difference between days since cb credit ended and how long before we applied for current credit\n",
    "diff_prev_curr_credit = bureau.DAYS_ENDDATE_FACT - bureau.DAYS_CREDIT\n",
    "diff_prev_curr_credit = diff_prev_curr_credit.groupby(bureau.SK_ID_CURR).mean()\n",
    "data.loc[:, 'mean_diff_ended_curr_credit'] = data.SK_ID_CURR.map(diff_prev_curr_credit)\n",
    "\n",
    "# mean of difference between days last credit ended and remaining duration of credit\n",
    "diff_prev_curr_credit = bureau.DAYS_ENDDATE_FACT - bureau.DAYS_CREDIT_ENDDATE\n",
    "diff_prev_curr_credit = diff_prev_curr_credit.groupby(bureau.SK_ID_CURR).mean()\n",
    "data.loc[:, 'mean_diff_prev_remaining_credit'] = data.SK_ID_CURR.map(diff_prev_curr_credit)\n",
    "\n",
    "# mean of ratio of two differences\n",
    "diff1 = bureau.DAYS_ENDDATE_FACT - bureau.DAYS_CREDIT\n",
    "diff2 = bureau.DAYS_CREDIT_ENDDATE - bureau.DAYS_CREDIT\n",
    "diff  = (diff1 / diff2).replace([np.inf, -np.inf], np.nan)\n",
    "diff  = diff.groupby(bureau.SK_ID_CURR).mean()\n",
    "data.loc[:, 'ratio_two_diff'] = data.SK_ID_CURR.map(diff)\n",
    "\n",
    "# number of null values in days credit end date\n",
    "if os.path.exists(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_num_nulls_enddate.pkl')):\n",
    "    num_nulls_enddate = pd.read_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_num_nulls_enddate.pkl'))\n",
    "else:    \n",
    "    num_nulls_enddate = bureau.groupby('SK_ID_CURR')['DAYS_CREDIT_ENDDATE'].apply(lambda x: x.isnull().sum())\n",
    "    num_nulls_enddate.to_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_num_nulls_enddate.pkl'))\n",
    "\n",
    "data.loc[:, 'num_nulls_enddate'] = data.SK_ID_CURR.map(num_nulls_enddate).fillna(-99).astype(np.int8)\n",
    "\n",
    "# ratio of debt to total credit sum\n",
    "ratio_debt_total                = (bureau.AMT_CREDIT_SUM_DEBT / (bureau.AMT_CREDIT_SUM + 1))\n",
    "ratio_debt_total                = ratio_debt_total.groupby(bureau.SK_ID_CURR).mean()\n",
    "data.loc[:, 'ratio_debt_total'] = data.SK_ID_CURR.map(ratio_debt_total)\n",
    "\n",
    "\n",
    "# merge back with original dataframe\n",
    "data.loc[:, 'num_prev_loans']           = data.SK_ID_CURR.map(prev_num_loans).fillna(0).values\n",
    "data.loc[:, 'num_prev_active_credits']  = data.SK_ID_CURR.map(num_active_credits).fillna(0).values\n",
    "data.loc[:, 'mean_credit_days_overdue'] = data.SK_ID_CURR.map(mean_days_overdue).fillna(0).values\n",
    "data.loc[:, 'mean_days_credit_end']     = data.SK_ID_CURR.map(mean_days_credit_end).fillna(0).values\n",
    "data.loc[:, 'mean_max_amt_overdue']     = data.SK_ID_CURR.map(mean_max_amt_overdue).fillna(0).values\n",
    "data.loc[:, 'mean_total_amt_overdue']   = data.SK_ID_CURR.map(mean_total_amt_overdue).values\n",
    "data.loc[:, 'sum_num_times_prolonged']  = data.SK_ID_CURR.map(sum_num_times_prolonged).fillna(0).astype(np.int8).values\n",
    "data.loc[:, 'mean_cb_credit_annuity']   = data.SK_ID_CURR.map(mean_cb_credit_annuity).fillna(0).values\n",
    "data.loc[:, 'std_cb_credit_annuity']    = data.SK_ID_CURR.map(std_cb_credit_annuity).fillna(0).values\n",
    "data.loc[:, 'num_diff_credits']         = data.SK_ID_CURR.map(num_diff_credits).fillna(0).values\n",
    "data.loc[:, 'mean_days_credit_update']  = data.SK_ID_CURR.map(mean_days_credit_update).fillna(0).values\n",
    "\n",
    "# load ratio credit overdue to credit sum\n",
    "# ratio_credit_overdue_sum = pd.read_pickle(os.path.join(basepath, 'data/processed/bureau_ratio_overdue_sum_credit.pkl'))\n",
    "# data.loc[:, 'ratio_cedit_overdue_sum'] = data.SK_ID_CURR.map(ratio_credit_overdue_sum).fillna(-1)\n",
    "\n",
    "# interaction between credit amount and duration of credit\n",
    "credit_times_duration = (bureau.AMT_CREDIT_SUM.fillna(0) *\\\n",
    "                         (bureau.DAYS_CREDIT_ENDDATE - bureau.DAYS_CREDIT).map(np.abs))\\\n",
    "                        .replace([np.inf, -np.inf], np.nan)\n",
    "credit_times_duration = credit_times_duration.groupby(bureau.SK_ID_CURR).mean()\n",
    "data.loc[:, 'credit_times_duration'] = data.SK_ID_CURR.map(credit_times_duration)\n",
    "\n",
    "\n",
    "#############################################################################################################\n",
    "#                      FEATURE INTERACTIONS                                                                 #\n",
    "#############################################################################################################\n",
    "\n",
    "# feature interaction between credit bureau annuity, current annuity and total income\n",
    "data.loc[:, 'ratio_cb_goods_annuity'] = (data.AMT_GOODS_PRICE / (data.mean_cb_credit_annuity + data.AMT_ANNUITY)).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# feature interaction between mean days credit update and last time id was changed by user\n",
    "data.loc[:, 'ratio_update_id']        = (data.mean_days_credit_update / data.DAYS_ID_PUBLISH).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# feature interaction between mean credit amount of previous credits with current credit\n",
    "data.loc[:, 'ratio_curr_prev_credit'] = data.AMT_CREDIT / data.AMT_CREDIT_SUM_mean\n",
    "\n",
    "#############################################################################################################\n",
    "#                           BUREAU and BUREAU BALANCE                                                       #\n",
    "#############################################################################################################\n",
    "\n",
    "prev_bal = bureau.loc[:, ['SK_ID_CURR', 'SK_ID_BUREAU']].merge(bureau_bal,\n",
    "                                                   on='SK_ID_BUREAU',\n",
    "                                                   how='left'\n",
    "                                                  )\n",
    "\n",
    "mean_status                      = prev_bal.groupby('SK_ID_BUREAU')['STATUS'].mean().fillna(-1)\n",
    "bureau.loc[:, 'mean_status'] = bureau.SK_ID_BUREAU.map(mean_status).values\n",
    "\n",
    "mean_status                = bureau.groupby('SK_ID_CURR')['mean_status'].mean()\n",
    "data.loc[:, 'mean_status'] = data.SK_ID_CURR.map(mean_status).values\n",
    "\n",
    "# previous loans history\n",
    "credit_history                = prev_bal.groupby('SK_ID_CURR').size().fillna(0)\n",
    "data.loc[:, 'credit_history'] = data.SK_ID_CURR.map(credit_history).values \n",
    "\n",
    "#############################################################################################################\n",
    "#                          PREVIOUS APPLICATION                                                             #\n",
    "#############################################################################################################\n",
    "\n",
    "# number of previous applications\n",
    "num_prev_apps                = prev_app.groupby('SK_ID_CURR').size()\n",
    "data.loc[:, 'num_prev_apps'] = data.SK_ID_CURR.map(num_prev_apps).fillna(0).astype(np.int8) \n",
    "\n",
    "# mean amount to be paid annually for previous applications\n",
    "prev_app_mean_annuity        = prev_app.groupby('SK_ID_CURR')['AMT_ANNUITY'].mean().map(lambda x: np.log(x + 1))\n",
    "prev_app_mean_annuity        = data.SK_ID_CURR.map(prev_app_mean_annuity)\n",
    "\n",
    "# ratio of previous annuity to current annuity\n",
    "data.loc[:, 'ratio_prev_curr_annuity'] = (prev_app_mean_annuity / data.AMT_ANNUITY).replace([np.inf, -np.inf], np.nan)\n",
    "data.loc[:, 'diff_prev_curr_annuity']  = (prev_app_mean_annuity - data.AMT_ANNUITY).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "\n",
    "# ratio of down payment amount to application amount sum\n",
    "if os.path.exists(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_down_payment_to_application.pkl')):\n",
    "    down_payment_to_application = pd.read_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_down_payment_to_application.pkl'))\n",
    "else:    \n",
    "    down_payment_to_application = prev_app.groupby('SK_ID_CURR').apply(lambda x: (x['AMT_DOWN_PAYMENT'].fillna(0) / x['AMT_APPLICATION']).sum())\n",
    "    down_payment_to_application.to_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_down_payment_to_application.pkl'))\n",
    "\n",
    "data.loc[:, 'down_payment_to_application'] = data.SK_ID_CURR.map(down_payment_to_application)\n",
    "\n",
    "# mean interest rate on down payments of previous applications\n",
    "mean_down_payment_rate                = prev_app.groupby('SK_ID_CURR')['RATE_DOWN_PAYMENT'].mean()\n",
    "data.loc[:, 'mean_down_payment_rate'] = data.SK_ID_CURR.map(mean_down_payment_rate)\n",
    "\n",
    "# most frequent rejection reason\n",
    "if os.path.exists(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_most_freq_reject_reason.pkl')):\n",
    "    most_freq_rejection_reason = pd.read_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_most_freq_reject_reason.pkl'))\n",
    "else:\n",
    "    most_freq_rejection_reason = prev_app.groupby('SK_ID_CURR').apply(lambda x: x.CODE_REJECT_REASON.value_counts().index.values[0])\n",
    "    most_freq_rejection_reason.to_pickle(os.path.join(basepath, f'data/processed/{DATASET_PREFIX}_most_freq_reject_reason.pkl'))\n",
    "\n",
    "data.loc[:, 'most_freq_rejection_reason'] = data.SK_ID_CURR.map(most_freq_rejection_reason)\n",
    "\n",
    "# median amount annuity\n",
    "median_annuity                = prev_app.groupby('SK_ID_CURR')['AMT_ANNUITY'].median().map(lambda x: np.log(x + 1))\n",
    "data.loc[:, 'median_annuity'] = data.SK_ID_CURR.map(median_annuity)\n",
    "\n",
    "# mean of past annuity to credit applications\n",
    "past_annuity_credit = (prev_app.AMT_ANNUITY / prev_app.AMT_CREDIT).replace([np.inf, -np.inf], np.nan)\n",
    "past_annuity_credit = past_annuity_credit.groupby(prev_app.SK_ID_CURR).mean()\n",
    "data.loc[:, 'past_annuity_to_credit'] = data.SK_ID_CURR.map(past_annuity_credit)\n",
    "\n",
    "\n",
    "# difference of down_payment * rate and annuity\n",
    "diff_dp_annuity = ((prev_app.AMT_DOWN_PAYMENT * prev_app.RATE_DOWN_PAYMENT) - prev_app.AMT_ANNUITY).replace([np.inf, -np.inf])\n",
    "diff_dp_annuity = diff_dp_annuity.groupby(prev_app.SK_ID_CURR).sum()\n",
    "data.loc[:, 'diff_dp_annuity'] = data.SK_ID_CURR.map(diff_dp_annuity)\n",
    "\n",
    "# mean of decision on last application\n",
    "mean_last_decision = prev_app.groupby('SK_ID_CURR')['DAYS_DECISION'].mean()\n",
    "data.loc[:, 'mean_last_decision'] = data.SK_ID_CURR.map(mean_last_decision)\n",
    "\n",
    "# mean of term of previous credit\n",
    "mean_prev_credit = prev_app.groupby('SK_ID_CURR')['CNT_PAYMENT'].mean()\n",
    "data.loc[:, 'mean_prev_credit'] = data.SK_ID_CURR.map(mean_prev_credit)\n",
    "\n",
    "\n",
    "# deviation in hour, weekday at which previous application process started\n",
    "dev_hour_process                = prev_app.groupby('SK_ID_CURR')['HOUR_APPR_PROCESS_START'].std()\n",
    "data.loc[:, 'dev_hour_process'] = data.SK_ID_CURR.map(dev_hour_process)\n",
    "\n",
    "dev_weekday_process                = prev_app.groupby('SK_ID_CURR')['WEEKDAY_APPR_PROCESS_START'].std()\n",
    "data.loc[:, 'dev_weekday_process'] = data.SK_ID_CURR.map(dev_weekday_process)\n",
    "\n",
    "# mean hour, weekday at which previous application process started\n",
    "dev_hour_process                 = prev_app.groupby('SK_ID_CURR')['HOUR_APPR_PROCESS_START'].mean()\n",
    "data.loc[:, 'mean_hour_process'] = data.SK_ID_CURR.map(dev_hour_process)\n",
    "\n",
    "dev_weekday_process                 = prev_app.groupby('SK_ID_CURR')['WEEKDAY_APPR_PROCESS_START'].mean()\n",
    "data.loc[:, 'mean_weekday_process'] = data.SK_ID_CURR.map(dev_weekday_process)\n",
    "\n",
    "# mean days before applicaiton was made\n",
    "prev_app_decision                = prev_app.groupby('SK_ID_CURR')['DAYS_DECISION'].mean()\n",
    "data.loc[:, 'prev_app_decision'] = data.SK_ID_CURR.map(prev_app_decision)\n",
    "\n",
    "# difference between termination of credit and day decision was made\n",
    "diff_termination_decision                = prev_app.DAYS_TERMINATION.replace({365243: np.nan}) - prev_app.DAYS_DECISION\n",
    "diff_termination_decision                = diff_termination_decision.groupby(prev_app.SK_ID_CURR).mean()\n",
    "data.loc[:, 'diff_termination_decision'] = data.SK_ID_CURR.map(diff_termination_decision)\n",
    "\n",
    "# ratio of amt annuity and amt goods price\n",
    "ratio_prev_annuity_goods                = (prev_app.AMT_ANNUITY / prev_app.AMT_GOODS_PRICE).replace([np.inf, -np.inf], np.nan)\n",
    "ratio_prev_annuity_goods                = ratio_prev_annuity_goods.groupby(prev_app.SK_ID_CURR).mean()\n",
    "data.loc[:, 'mean_prev_annuity_goods']  = data.SK_ID_CURR.map(ratio_prev_annuity_goods)\n",
    "\n",
    "# max of ratio of amt annuity to amt goods price\n",
    "ratio_prev_annuity_goods                = (prev_app.AMT_ANNUITY / prev_app.AMT_GOODS_PRICE).replace([np.inf, -np.inf], np.nan)\n",
    "ratio_prev_annuity_goods                = ratio_prev_annuity_goods.groupby(prev_app.SK_ID_CURR).max()\n",
    "data.loc[:, 'max_prev_annuity_goods'] = data.SK_ID_CURR.map(ratio_prev_annuity_goods)\n",
    "\n",
    "\n",
    "# max of ratio of amt annuity to amt_credit_sum\n",
    "ratio_prev_annuity_credit                = (prev_app.AMT_ANNUITY / prev_app.AMT_CREDIT).replace([np.inf, -np.inf], np.nan)\n",
    "ratio_prev_annuity_credit                = ratio_prev_annuity_goods.groupby(prev_app.SK_ID_CURR).max()\n",
    "data.loc[:, 'max_prev_annuity_credit']   = data.SK_ID_CURR.map(ratio_prev_annuity_credit)\n",
    "\n",
    "\n",
    "# most recent previous application\n",
    "most_recent_prev_app = prev_app.groupby('SK_ID_CURR')['DAYS_DECISION'].max()\n",
    "data.loc[:, 'most_recent_prev_application'] = data.SK_ID_CURR.map(most_recent_prev_app)\n",
    "\n",
    "###############################################################################################################\n",
    "#                                 POS CASH                                                                    #\n",
    "###############################################################################################################\n",
    "data, cif_cols = get_agg_features(data, pos_cash, 'CNT_INSTALMENT_FUTURE', 'SK_ID_CURR')\n",
    "\n",
    "# mean of term of previous credits\n",
    "mean_term = pos_cash.groupby('SK_ID_CURR')['CNT_INSTALMENT'].mean()\n",
    "data.loc[:, 'mean_term'] = data.SK_ID_CURR.map(mean_term)\n",
    "\n",
    "# total number of installments\n",
    "total_installments                = pos_cash.CNT_INSTALMENT + pos_cash.CNT_INSTALMENT_FUTURE\n",
    "total_installments                = total_installments.groupby(pos_cash.SK_ID_CURR).sum()\n",
    "data.loc[:, 'total_installments'] = data.SK_ID_CURR.map(total_installments)\n",
    "\n",
    "# ratio of paid to unpaid number of installments\n",
    "ratio_paid_unpaid = (pos_cash.CNT_INSTALMENT_FUTURE / pos_cash.CNT_INSTALMENT).replace([np.inf, -np.inf], np.nan)\n",
    "ratio_paid_unpaid = ratio_paid_unpaid.groupby(pos_cash.SK_ID_CURR).mean()\n",
    "data.loc[:, 'ratio_paid_unpaid'] = data.SK_ID_CURR.map(ratio_paid_unpaid)\n",
    "\n",
    "##############################################################################################################\n",
    "#                                Credit Card Balance                                                         #\n",
    "##############################################################################################################\n",
    "\n",
    "# mean of amount balance during previous payments\n",
    "mean_amt_balance = credit_bal.groupby('SK_ID_CURR')['AMT_BALANCE'].mean()\n",
    "data.loc[:, 'mean_amt_balance'] = data.SK_ID_CURR.map(mean_amt_balance)\n",
    "\n",
    "# mean of actual credit limit\n",
    "mean_credit_limit = credit_bal.groupby('SK_ID_CURR')['AMT_CREDIT_LIMIT_ACTUAL'].mean()\n",
    "data.loc[:, 'mean_credit_limit'] = data.SK_ID_CURR.map(mean_credit_limit)\n",
    "\n",
    "# total paid installments on previous credit\n",
    "total_paid_installments = credit_bal.groupby('SK_ID_CURR')['CNT_INSTALMENT_MATURE_CUM'].sum()\n",
    "data.loc[:, 'total_paid_installments'] = data.SK_ID_CURR.map(total_paid_installments)\n",
    "\n",
    "# mean total drawings\n",
    "mean_total_drawings                = credit_bal.groupby('SK_ID_CURR')['AMT_DRAWINGS_CURRENT'].mean()\n",
    "data.loc[:, 'mean_total_drawings'] = data.SK_ID_CURR.map(mean_total_drawings)\n",
    "\n",
    "# sum of diff between balance and credit limit\n",
    "diff_bal_credit   = credit_bal.AMT_BALANCE - credit_bal.AMT_CREDIT_LIMIT_ACTUAL\n",
    "diff_bal_credit   = diff_bal_credit.groupby(credit_bal.SK_ID_CURR).sum()\n",
    "\n",
    "data.loc[:, 'diff_bal_credit'] = data.SK_ID_CURR.map(diff_bal_credit)\n",
    "\n",
    "# mean of ratio of balance and credit limit\n",
    "ratio_bal_credit = credit_bal.AMT_BALANCE / credit_bal.AMT_CREDIT_LIMIT_ACTUAL\n",
    "ratio_bal_credit = ratio_bal_credit.groupby(credit_bal.SK_ID_CURR).mean()\n",
    "\n",
    "data.loc[:, 'ratio_bal_credit'] = data.SK_ID_CURR.map(ratio_bal_credit)\n",
    "\n",
    "# aggregate features for MONTHS_BALANCE\n",
    "data, mb_cols = get_agg_features(data, credit_bal, 'MONTHS_BALANCE', 'SK_ID_CURR')\n",
    "\n",
    "\n",
    "# ratio of minimum installment on credit card with amount balance\n",
    "ratio_min_installment_balance                = (credit_bal.AMT_BALANCE / credit_bal.AMT_INST_MIN_REGULARITY).replace([np.inf, -np.inf], np.nan)\n",
    "ratio_min_installment_balance                = ratio_min_installment_balance.groupby(credit_bal.SK_ID_CURR).mean()\n",
    "data.loc[:, 'ratio_min_installment_balance'] = data.SK_ID_CURR.map(ratio_min_installment_balance)\n",
    "\n",
    "# difference of minimum installment on credit card with amount balance\n",
    "diff_min_installment_balance                = (credit_bal.AMT_BALANCE - credit_bal.AMT_INST_MIN_REGULARITY).replace([np.inf, -np.inf], np.nan)\n",
    "diff_min_installment_balance                = diff_min_installment_balance.groupby(credit_bal.SK_ID_CURR).mean().map(lambda x: np.log(x + 1))\n",
    "data.loc[:, 'diff_min_installment_balance'] = data.SK_ID_CURR.map(diff_min_installment_balance)\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "#                                  Installment Payments                                                       #\n",
    "###############################################################################################################\n",
    "\n",
    "# mean installment\n",
    "mean_installment                = installments.groupby('SK_ID_CURR')['AMT_INSTALMENT'].mean()\n",
    "data.loc[:, 'mean_installment'] = data.SK_ID_CURR.map(mean_installment)\n",
    "\n",
    "# mean payment against installment\n",
    "data, ap_cols               = get_agg_features(data, installments, 'AMT_PAYMENT', 'SK_ID_CURR')\n",
    "\n",
    "# difference between actual day of installment versus when it was supposed to be paid\n",
    "\n",
    "diff_actual_decided = -(installments.DAYS_ENTRY_PAYMENT - installments.DAYS_INSTALMENT)\n",
    "diff_actual_decided = diff_actual_decided.groupby(installments.SK_ID_CURR).mean()\n",
    "\n",
    "data.loc[:, 'diff_actual_decided'] = data.SK_ID_CURR.map(diff_actual_decided)\n",
    "\n",
    "# ratio of installment to be paid versus actual amount paid\n",
    "\n",
    "res = (installments.AMT_INSTALMENT / installments.AMT_PAYMENT).replace([np.inf, -np.inf], np.nan)\n",
    "res = res.groupby(installments.SK_ID_CURR).mean()\n",
    "\n",
    "data.loc[:, 'ratio_actual_decided_amount'] = data.SK_ID_CURR.map(res)\n",
    "\n",
    "###############################################################################################################\n",
    "#                                Previous and Current Application                                             #   \n",
    "###############################################################################################################\n",
    "\n",
    "# ratio of mean of amount credit sum from previous applications and current amount credit sum\n",
    "prev_amt_credit_mean = prev_app.groupby('SK_ID_CURR')['AMT_CREDIT'].mean()\n",
    "prev_amt_credit_mean = data.SK_ID_CURR.map(prev_amt_credit_mean)\n",
    "\n",
    "data.loc[:, 'ratio_prev_curr_credit'] = (data.AMT_CREDIT / prev_amt_credit_mean)\\\n",
    "                                             .replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "\n",
    "# diff (amt_annuity / amt_credit) current and previous application\n",
    "ratio_annuity_credit = (prev_app.AMT_ANNUITY / prev_app.AMT_CREDIT).replace([np.inf, -np.inf], np.nan)\n",
    "ratio_annuity_credit = ratio_annuity_credit.groupby(prev_app.SK_ID_CURR).mean()\n",
    "data.loc[:, 'diff_annuity_credit_curr_prev'] = data.ratio_annuity_credit - ratio_annuity_credit\n",
    "\n",
    "\n",
    "# diff (amt_goods_price / amt_credit_sum) current and previous application\n",
    "ratio_goods_credit = (prev_app.AMT_GOODS_PRICE / prev_app.AMT_CREDIT).replace([np.inf, -np.inf], np.nan)\n",
    "ratio_goods_credit = ratio_goods_credit.groupby(prev_app.SK_ID_CURR).mean()\n",
    "data.loc[:, 'diff_credit_goods_curr_prev'] = data.ratio_goods_credit - ratio_goods_credit\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "#                               Previous Application and Bureau                                               #\n",
    "###############################################################################################################\n",
    "\n",
    "\n",
    "# difference between day decision was made and remaining duration of CB Credit\n",
    "dcn = bureau.groupby('SK_ID_CURR')['DAYS_CREDIT_ENDDATE'].mean()\n",
    "dd  = prev_app.groupby('SK_ID_CURR')['DAYS_DECISION'].mean()\n",
    "data.loc[:, 'diff_decision_credit_end'] = data.SK_ID_CURR.map(dd - dcn)\n",
    "\n",
    "dcu = bureau.groupby('SK_ID_CURR')['DAYS_CREDIT_UPDATE'].mean() \n",
    "dd  = prev_app.groupby('SK_ID_CURR')['DAYS_DECISION'].mean()\n",
    "data.loc[:, 'diff_decision_update'] = data.SK_ID_CURR.map(dd - dcu)\n",
    "\n",
    "df  = bureau.groupby('SK_ID_CURR')['DAYS_ENDDATE_FACT'].mean() \n",
    "dd  = prev_app.groupby('SK_ID_CURR')['DAYS_DECISION'].mean()\n",
    "data.loc[:, 'diff_decision_fact'] = data.SK_ID_CURR.map(dd - df)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# delete all intermediatory variables\n",
    "del prev_num_loans, num_active_credits, bureau\n",
    "del mean_days_overdue, mean_days_credit_end\n",
    "del mean_max_amt_overdue, sum_num_times_prolonged\n",
    "del mean_cb_credit_annuity, std_cb_credit_annuity\n",
    "del num_diff_credits, mean_days_credit_update\n",
    "del mean_status, prev_bal, credit_history\n",
    "del num_prev_apps\n",
    "del prev_app, down_payment_to_application\n",
    "del mean_down_payment_rate, most_freq_rejection_reason\n",
    "del median_annuity\n",
    "del latest_credit, credit_duration\n",
    "del mean_total_amt_overdue, credit_times_duration\n",
    "del past_annuity_credit, mean_last_decision\n",
    "del credit_bal, mean_amt_balance, mean_credit_limit\n",
    "del total_paid_installments, mean_total_drawings\n",
    "del diff_bal_credit, diff_prev_curr_credit\n",
    "del diff1, diff2, diff, num_nulls_enddate\n",
    "del ratio_debt_total, ratio_min_installment_balance\n",
    "del diff_min_installment_balance\n",
    "del total_installments, prev_amt_credit_mean\n",
    "del dev_weekday_process, dev_hour_process\n",
    "del prev_app_decision, diff_termination_decision\n",
    "del ratio_prev_annuity_goods, dcn, dd, dcu, df\n",
    "del ratio_prev_annuity_credit, diff_actual_decided\n",
    "del most_recent_prev_app\n",
    "\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: CNT_CHILDREN\n",
      "Feature: num_nulls_enddate\n",
      "Feature: num_prev_apps\n"
     ]
    }
   ],
   "source": [
    "# replace feature values with frequency less 20 with -100\n",
    "for f in data.select_dtypes(include=['int8']).columns:\n",
    "    if data[f].nunique() > 10:        \n",
    "        low_freq_values = data[f].value_counts()\n",
    "        low_freq_values = low_freq_values[low_freq_values < 20].index.values\n",
    "        \n",
    "        if len(low_freq_values) > 0:\n",
    "            print('Feature: {}'.format(f))\n",
    "            data.loc[data[f].isin(low_freq_values), f] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ratio_min_installment_balance    0.803803\n",
       "diff_min_installment_balance     0.713548\n",
       "ratio_bal_credit                 0.712010\n",
       "mean_amt_balance                 0.709315\n",
       "mean_total_drawings              0.709315\n",
       "total_paid_installments          0.709315\n",
       "MONTHS_BALANCE_mean              0.709315\n",
       "MONTHS_BALANCE_median            0.709315\n",
       "MONTHS_BALANCE_amax              0.709315\n",
       "MONTHS_BALANCE_var               0.709315\n",
       "MONTHS_BALANCE_amin              0.709315\n",
       "MONTHS_BALANCE_sum               0.709315\n",
       "diff_bal_credit                  0.709315\n",
       "mean_credit_limit                0.709315\n",
       "COMMONAREA_MODE                  0.697141\n",
       "COMMONAREA_MEDI                  0.697141\n",
       "COMMONAREA_AVG                   0.697141\n",
       "NONLIVINGAPARTMENTS_AVG          0.692933\n",
       "NONLIVINGAPARTMENTS_MEDI         0.692933\n",
       "NONLIVINGAPARTMENTS_MODE         0.692933\n",
       "LIVINGAPARTMENTS_AVG             0.682037\n",
       "LIVINGAPARTMENTS_MODE            0.682037\n",
       "LIVINGAPARTMENTS_MEDI            0.682037\n",
       "FLOORSMIN_MODE                   0.676785\n",
       "FLOORSMIN_AVG                    0.676785\n",
       "FLOORSMIN_MEDI                   0.676785\n",
       "YEARS_BUILD_AVG                  0.663306\n",
       "YEARS_BUILD_MEDI                 0.663306\n",
       "YEARS_BUILD_MODE                 0.663306\n",
       "ratio_car_person_age             0.660316\n",
       "                                   ...   \n",
       "WALLSMATERIAL_MODE               0.000000\n",
       "SK_ID_CURR                       0.000000\n",
       "REG_REGION_NOT_WORK_REGION       0.000000\n",
       "REG_REGION_NOT_LIVE_REGION       0.000000\n",
       "FLAG_EMAIL                       0.000000\n",
       "FLAG_EMP_PHONE                   0.000000\n",
       "FLAG_MOBIL                       0.000000\n",
       "FLAG_OWN_CAR                     0.000000\n",
       "FLAG_OWN_REALTY                  0.000000\n",
       "FLAG_PHONE                       0.000000\n",
       "FLAG_WORK_PHONE                  0.000000\n",
       "FONDKAPREMONT_MODE               0.000000\n",
       "HOUR_APPR_PROCESS_START          0.000000\n",
       "HOUSETYPE_MODE                   0.000000\n",
       "LIVE_CITY_NOT_WORK_CITY          0.000000\n",
       "LIVE_REGION_NOT_WORK_REGION      0.000000\n",
       "NAME_CONTRACT_TYPE               0.000000\n",
       "NAME_EDUCATION_TYPE              0.000000\n",
       "NAME_FAMILY_STATUS               0.000000\n",
       "NAME_INCOME_TYPE                 0.000000\n",
       "NAME_TYPE_SUITE                  0.000000\n",
       "OCCUPATION_TYPE                  0.000000\n",
       "ORGANIZATION_TYPE                0.000000\n",
       "num_prev_apps                    0.000000\n",
       "REGION_POPULATION_RELATIVE       0.000000\n",
       "REGION_RATING_CLIENT             0.000000\n",
       "REGION_RATING_CLIENT_W_CITY      0.000000\n",
       "REG_CITY_NOT_LIVE_CITY           0.000000\n",
       "REG_CITY_NOT_WORK_CITY           0.000000\n",
       "NAME_HOUSING_TYPE                0.000000\n",
       "Length: 256, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.isnull().sum() / len(data)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unpack to train and test\n",
    "tr = data.iloc[:ntrain]\n",
    "te = data.iloc[ntrain:]\n",
    "\n",
    "del data\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLS_TO_REMOVE = [\n",
    "                  'FLAG_DOCUMENT_21',\n",
    "                  'FLAG_DOCUMENT_4',\n",
    "                  'FLAG_MOBIL',\n",
    "                  'FLAG_DOCUMENT_2',\n",
    "                  'FLAG_DOCUMENT_20',\n",
    "                  'FLAG_DOCUMENT_9',\n",
    "                  'FLAG_DOCUMENT_17',\n",
    "                  'FLAG_DOCUMENT_19',\n",
    "                  'FLAG_DOCUMENT_5',\n",
    "                  'FLAG_CONT_MOBILE',\n",
    "                  'FLAG_DOCUMENT_10',\n",
    "                  'HOUSETYPE_MODE',\n",
    "                  'FLAG_DOCUMENT_12',\n",
    "                  'FLAG_DOCUMENT_7',\n",
    "                  'FLAG_DOCUMENT_11',\n",
    "                  'AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "                  'LIVE_REGION_NOT_WORK_REGION',\n",
    "                  'AMT_REQ_CREDIT_BUREAU_DAY',\n",
    "                  'FLAG_DOCUMENT_15',\n",
    "                  'EMERGENCYSTATE_MODE',\n",
    "                  'REG_REGION_NOT_LIVE_REGION',\n",
    "                  'SK_ID_CURR',\n",
    "                  'FLAG_EMP_PHONE',\n",
    "                  'REG_REGION_NOT_WORK_REGION',\n",
    "                  'FLAG_DOCUMENT_14',\n",
    "                  'FLAG_DOCUMENT_6',\n",
    "                  'sum_num_times_prolonged',\n",
    "                  'TARGET'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [f for f in tr.columns if f not in COLS_TO_REMOVE]\n",
    "\n",
    "Xtr  = tr.loc[:, features]\n",
    "ytr  = tr.loc[:, 'TARGET']\n",
    "\n",
    "Xval = te.loc[:, features]\n",
    "# yval = te.loc[:, 'TARGET'] # only execute during validation phase\n",
    "\n",
    "del tr, te\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features used in the model are: 228\n"
     ]
    }
   ],
   "source": [
    "print('Number of features used in the model are: {}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[20]\ttrain's auc: 0.735859\tval's auc: 0.726051\n",
      "[40]\ttrain's auc: 0.742364\tval's auc: 0.729388\n",
      "[60]\ttrain's auc: 0.748059\tval's auc: 0.733093\n",
      "[80]\ttrain's auc: 0.755723\tval's auc: 0.738513\n",
      "[100]\ttrain's auc: 0.763089\tval's auc: 0.744642\n",
      "[120]\ttrain's auc: 0.769919\tval's auc: 0.748983\n",
      "[140]\ttrain's auc: 0.77659\tval's auc: 0.753622\n",
      "[160]\ttrain's auc: 0.782951\tval's auc: 0.758065\n",
      "[180]\ttrain's auc: 0.78872\tval's auc: 0.761832\n",
      "[200]\ttrain's auc: 0.794223\tval's auc: 0.765409\n",
      "[220]\ttrain's auc: 0.799643\tval's auc: 0.768748\n",
      "[240]\ttrain's auc: 0.804509\tval's auc: 0.771427\n",
      "[260]\ttrain's auc: 0.808935\tval's auc: 0.773457\n",
      "[280]\ttrain's auc: 0.813085\tval's auc: 0.77525\n",
      "[300]\ttrain's auc: 0.817035\tval's auc: 0.776762\n",
      "[320]\ttrain's auc: 0.82071\tval's auc: 0.778022\n",
      "[340]\ttrain's auc: 0.824256\tval's auc: 0.779108\n",
      "[360]\ttrain's auc: 0.827702\tval's auc: 0.780003\n",
      "[380]\ttrain's auc: 0.83119\tval's auc: 0.780827\n",
      "[400]\ttrain's auc: 0.834357\tval's auc: 0.781488\n",
      "[420]\ttrain's auc: 0.837475\tval's auc: 0.782118\n",
      "[440]\ttrain's auc: 0.840625\tval's auc: 0.782767\n",
      "[460]\ttrain's auc: 0.843576\tval's auc: 0.783283\n",
      "[480]\ttrain's auc: 0.846442\tval's auc: 0.783746\n",
      "[500]\ttrain's auc: 0.849217\tval's auc: 0.784134\n",
      "[520]\ttrain's auc: 0.851929\tval's auc: 0.784341\n",
      "[540]\ttrain's auc: 0.854623\tval's auc: 0.784797\n",
      "[560]\ttrain's auc: 0.857235\tval's auc: 0.785161\n",
      "[580]\ttrain's auc: 0.859711\tval's auc: 0.785444\n",
      "[600]\ttrain's auc: 0.862244\tval's auc: 0.785731\n",
      "[620]\ttrain's auc: 0.864721\tval's auc: 0.785955\n",
      "[640]\ttrain's auc: 0.86693\tval's auc: 0.786025\n",
      "[660]\ttrain's auc: 0.869191\tval's auc: 0.786302\n",
      "[680]\ttrain's auc: 0.87137\tval's auc: 0.786425\n",
      "[700]\ttrain's auc: 0.873513\tval's auc: 0.786475\n",
      "[720]\ttrain's auc: 0.875632\tval's auc: 0.7866\n",
      "[740]\ttrain's auc: 0.877556\tval's auc: 0.786709\n",
      "[760]\ttrain's auc: 0.879632\tval's auc: 0.78686\n",
      "[780]\ttrain's auc: 0.881627\tval's auc: 0.78689\n",
      "[800]\ttrain's auc: 0.883586\tval's auc: 0.786952\n",
      "[820]\ttrain's auc: 0.885384\tval's auc: 0.787087\n",
      "[840]\ttrain's auc: 0.887146\tval's auc: 0.787072\n",
      "[860]\ttrain's auc: 0.888946\tval's auc: 0.787067\n",
      "[880]\ttrain's auc: 0.8907\tval's auc: 0.787053\n",
      "[900]\ttrain's auc: 0.892383\tval's auc: 0.787073\n",
      "[920]\ttrain's auc: 0.894025\tval's auc: 0.787162\n",
      "[940]\ttrain's auc: 0.895638\tval's auc: 0.787223\n",
      "[960]\ttrain's auc: 0.89726\tval's auc: 0.787251\n",
      "[980]\ttrain's auc: 0.898757\tval's auc: 0.787208\n",
      "[1000]\ttrain's auc: 0.900362\tval's auc: 0.787209\n",
      "[1020]\ttrain's auc: 0.901926\tval's auc: 0.787161\n",
      "[1040]\ttrain's auc: 0.903458\tval's auc: 0.787197\n",
      "[1060]\ttrain's auc: 0.904987\tval's auc: 0.787245\n",
      "[1080]\ttrain's auc: 0.906489\tval's auc: 0.787294\n",
      "[1100]\ttrain's auc: 0.907991\tval's auc: 0.787246\n",
      "[1120]\ttrain's auc: 0.909383\tval's auc: 0.787208\n",
      "[1140]\ttrain's auc: 0.91069\tval's auc: 0.787231\n",
      "[1160]\ttrain's auc: 0.912066\tval's auc: 0.787163\n",
      "Early stopping, best iteration is:\n",
      "[1068]\ttrain's auc: 0.905613\tval's auc: 0.787326\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': .02,\n",
    "    'metric': 'auc',\n",
    "    'min_data_in_leaf': 100,\n",
    "    'num_leaves': 64,\n",
    "    'feature_fraction': .65,\n",
    "    'bagging_fraction': .8,\n",
    "    'lambda_l1': 5,\n",
    "    'lambda_l2': 10,\n",
    "    'min_child_weight': 1.,\n",
    "    'nthread': 4\n",
    "}\n",
    "\n",
    "ltrain = lgb.Dataset(Xtr, ytr, feature_name=features)\n",
    "lval   = lgb.Dataset(Xval, yval, feature_name=features)\n",
    "\n",
    "valid_sets  = [ltrain, lval]\n",
    "valid_names = ['train', 'val']\n",
    "\n",
    "num_boost_round       = 5000\n",
    "early_stopping_rounds = 100\n",
    "\n",
    "m = lgb.train(params, \n",
    "              ltrain, \n",
    "              num_boost_round, \n",
    "              valid_sets=valid_sets, \n",
    "              valid_names=valid_names, \n",
    "              early_stopping_rounds=early_stopping_rounds, \n",
    "              verbose_eval=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[1068]\ttrain's auc: 0.905613\tval's auc: 0.787326`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>ratio_annuity_credit</td>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>AMT_PAYMENT_sum</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DAYS_BIRTH</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>EXT_SOURCE_SUM</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>ratio_debt_total</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>EXT_SOURCE_2</td>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>diff_actual_decided</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>EXT_SOURCE_3</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>ratio_paid_unpaid</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>ratio_actual_decided_amount</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>DAYS_CREDIT_amax</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>AMT_PAYMENT_amin</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>ratio_annuity_score_3</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CNT_INSTALMENT_FUTURE_var</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>ratio_goods_credit</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>mean_prev_credit</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>ratio_annuity_score_1</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>ratio_annuity_score_2</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>dev_hour_process</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>diff_termination_decision</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>diff_dp_annuity</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>most_recent_prev_application</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>age_plus_employed</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>ratio_credit_annuity_score_3</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>EXT_SOURCE_1</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>mean_last_decision</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>AMT_PAYMENT_median</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>AMT_PAYMENT_amax</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>mean_diff_ended_curr_credit</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>dev_weekday_process</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>WALLSMATERIAL_MODE</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ENTRANCES_MEDI</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>NONLIVINGAPARTMENTS_AVG</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FLAG_DOCUMENT_18</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>FLOORSMIN_MODE</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>FLOORSMIN_MEDI</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>REGION_RATING_CLIENT</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ENTRANCES_MODE</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CNT_CHILDREN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>CNT_INSTALMENT_FUTURE_amin</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>FLOORSMAX_MEDI</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>NAME_TYPE_SUITE</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FLOORSMAX_MODE</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>NAME_CONTRACT_TYPE</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMT_REQ_CREDIT_BUREAU_WEEK</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ELEVATORS_MEDI</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>FLAG_OWN_CAR</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>REG_CITY_NOT_WORK_CITY</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>LIVE_CITY_NOT_WORK_CITY</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMT_REQ_CREDIT_BUREAU_MON</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>MONTHS_BALANCE_amax</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>FLAG_DOCUMENT_13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FLAG_OWN_REALTY</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ELEVATORS_MODE</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>NONLIVINGAPARTMENTS_MODE</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>FONDKAPREMONT_MODE</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>FLAG_DOCUMENT_8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FLAG_EMAIL</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>FLAG_DOCUMENT_16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>mean_credit_days_overdue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         features   imp\n",
       "113          ratio_annuity_credit  1175\n",
       "219               AMT_PAYMENT_sum  1037\n",
       "20                     DAYS_BIRTH  1018\n",
       "96                 EXT_SOURCE_SUM   959\n",
       "152              ratio_debt_total   950\n",
       "34                   EXT_SOURCE_2   896\n",
       "220           diff_actual_decided   828\n",
       "35                   EXT_SOURCE_3   788\n",
       "198             ratio_paid_unpaid   786\n",
       "221   ratio_actual_decided_amount   761\n",
       "134              DAYS_CREDIT_amax   742\n",
       "218              AMT_PAYMENT_amin   731\n",
       "119         ratio_annuity_score_3   720\n",
       "193     CNT_INSTALMENT_FUTURE_var   708\n",
       "111            ratio_goods_credit   702\n",
       "179              mean_prev_credit   664\n",
       "117         ratio_annuity_score_1   662\n",
       "118         ratio_annuity_score_2   656\n",
       "180              dev_hour_process   655\n",
       "185     diff_termination_decision   645\n",
       "177               diff_dp_annuity   615\n",
       "189  most_recent_prev_application   612\n",
       "106             age_plus_employed   607\n",
       "122  ratio_credit_annuity_score_3   606\n",
       "33                   EXT_SOURCE_1   605\n",
       "178            mean_last_decision   584\n",
       "215            AMT_PAYMENT_median   572\n",
       "216              AMT_PAYMENT_amax   568\n",
       "148   mean_diff_ended_curr_credit   560\n",
       "181           dev_weekday_process   557\n",
       "..                            ...   ...\n",
       "87             WALLSMATERIAL_MODE    46\n",
       "31                 ENTRANCES_MEDI    46\n",
       "70        NONLIVINGAPARTMENTS_AVG    45\n",
       "38               FLAG_DOCUMENT_18    39\n",
       "51                 FLOORSMIN_MODE    38\n",
       "50                 FLOORSMIN_MEDI    38\n",
       "82           REGION_RATING_CLIENT    38\n",
       "32                 ENTRANCES_MODE    38\n",
       "14                   CNT_CHILDREN    37\n",
       "194    CNT_INSTALMENT_FUTURE_amin    36\n",
       "47                 FLOORSMAX_MEDI    29\n",
       "69                NAME_TYPE_SUITE    28\n",
       "48                 FLOORSMAX_MODE    26\n",
       "64             NAME_CONTRACT_TYPE    22\n",
       "6      AMT_REQ_CREDIT_BUREAU_WEEK    20\n",
       "28                 ELEVATORS_MEDI    20\n",
       "42                   FLAG_OWN_CAR    20\n",
       "85         REG_CITY_NOT_WORK_CITY    17\n",
       "57        LIVE_CITY_NOT_WORK_CITY    16\n",
       "4       AMT_REQ_CREDIT_BUREAU_MON    16\n",
       "207           MONTHS_BALANCE_amax    14\n",
       "36               FLAG_DOCUMENT_13    14\n",
       "43                FLAG_OWN_REALTY    13\n",
       "29                 ELEVATORS_MODE    13\n",
       "72       NONLIVINGAPARTMENTS_MODE    10\n",
       "52             FONDKAPREMONT_MODE     8\n",
       "40                FLAG_DOCUMENT_8     7\n",
       "41                     FLAG_EMAIL     6\n",
       "37               FLAG_DOCUMENT_16     3\n",
       "155      mean_credit_days_overdue     1\n",
       "\n",
       "[228 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature importance df\n",
    "feat_imp = pd.DataFrame({'features': features,\n",
    "                         'imp': m.feature_importance()\n",
    "                        })\n",
    "\n",
    "feat_imp.sort_values(by='imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>most_recent_prev_application</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         features  imp\n",
       "189  most_recent_prev_application  612"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp[feat_imp.features == 'most_recent_prev_application']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOF Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.7 s, sys: 163 ms, total: 15.8 s\n",
      "Wall time: 4.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "HOLDOUT_SCORE  = 0.787326\n",
    "\n",
    "oof_preds = m.predict(Xval)\n",
    "joblib.dump(oof_preds, os.path.join(basepath, f'data/oof_sub/{MODEL_PRESET}_{HOLDOUT_SCORE}_preds.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31min 7s, sys: 3.49 s, total: 31min 11s\n",
      "Wall time: 8min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': (.02 / 1.2),\n",
    "    'metric': 'auc',\n",
    "    'min_data_in_leaf': 100,\n",
    "    'num_leaves': 64,\n",
    "    'feature_fraction': .65,\n",
    "    'bagging_fraction': .8,\n",
    "    'lambda_l1': 5,\n",
    "    'lambda_l2': 10,\n",
    "    'min_child_weight': 1.,\n",
    "    'nthread': 4\n",
    "}\n",
    "\n",
    "BEST_ITERATION  = 1068\n",
    "\n",
    "num_boost_round = int(BEST_ITERATION * 1.2)\n",
    "ltrain          = lgb.Dataset(Xtr, ytr, feature_name=features)\n",
    "\n",
    "m           = lgb.train(params, ltrain, num_boost_round)\n",
    "final_preds = m.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOLDOUT_SCORE  = 0.787326\n",
    "\n",
    "sub_identifier = \"%s-%s-%.5f\" % (datetime.now().strftime('%Y%m%d-%H%M'), MODEL_PRESET, HOLDOUT_SCORE)\n",
    "\n",
    "sub           = pd.read_csv('../data/raw/sample_submission.csv.zip')\n",
    "sub['TARGET'] = final_preds\n",
    "\n",
    "sub.to_csv(os.path.join(basepath, 'submissions/%s.csv'%(sub_identifier)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
